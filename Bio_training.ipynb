{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bio_training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marel88/Bioinfo_7_1/blob/master/Bio_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LzELL8aM7GgM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**FOR GOOGLE DRIVE IMPORT**"
      ]
    },
    {
      "metadata": {
        "id": "V752DLAGyHSt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Auth Code: **  4/OAHVO-FYe-We-bQDjlsGLYHCnoXXO7QhiqEVqnID3ZwYv8rbWxamVQI\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "u3ONVKn-7eZI",
        "colab_type": "code",
        "outputId": "1ed9d1c5-4864-4be2-fe99-16e47183085c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G0EP9-6VtU73",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DATASET PRE PROCESSING**"
      ]
    },
    {
      "metadata": {
        "id": "H4oUSSOuy7VP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "71a8ee34-4562-4df1-a23b-31573e91ddaf"
      },
      "cell_type": "code",
      "source": [
        "!pip install py_wsi --no-index --find-links file:///Users/Mac/Desktop/py-wsi-1.1.zip\n",
        "!apt install openslide-tool\n",
        "!pip install openslide-python\n",
        "\n",
        "#SCRIPT FOR IMAGE CROPPING\n",
        "\n",
        "\n",
        "import py_wsi\n",
        "import py_wsi.imagepy_toolkit as tk\n",
        "from py_wsi import turtle\n",
        "from pathlib import Path\n",
        "\n",
        "#file_dir = \"/Users/Mac/Desktop/ROI-dataset-bioinf/\"\n",
        "location = \"/Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/\"\n",
        "\n",
        "def wsi_cropping(path):\n",
        "    folders = [path + \"/Healthy/\", path + \"/Benign/\", path + \"/Cancer/\"]\n",
        "    \n",
        "    for folder in folders:\n",
        "        file_dir=folder\n",
        "        p = Path(folder)\n",
        "        part = p.parts\n",
        "        db_location= location + part[5] + part[0] + part[6] + part[0]\n",
        "        print(file_dir)\n",
        "        print(db_location)\n",
        "        \n",
        "        xml_dir = file_dir\n",
        "        patch_size = 224\n",
        "        level = 10\n",
        "        db_name = \"\"\n",
        "        overlap = 0\n",
        "\n",
        "        # All possible labels mapped to integer ids in order of increasing severity.\n",
        "        label_map = {}\n",
        "\n",
        "        turtle_obj = turtle.Turtle(file_dir, db_location, db_name, xml_dir=xml_dir, label_map=label_map, storage_type='disk')\n",
        "        turtle_obj.sample_and_store_patches(patch_size, level, overlap, load_xml=False, limit_bounds=True)\n",
        "        \n",
        "    return;"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: file:///Users/Mac/Desktop/py-wsi-1.1.zip\r\n",
            "Requirement already satisfied: py_wsi in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.1)\r\n",
            "Requirement already satisfied: shapely in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from py_wsi) (1.6.4.post2)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from py_wsi) (1.14.6)\n",
            "Requirement already satisfied: openslide-python in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from py_wsi) (1.1.1)\n",
            "Requirement already satisfied: lmdb in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from py_wsi) (0.94)\n",
            "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from py_wsi) (6.0.0)\n",
            "Unable to locate an executable at \"/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/bin/apt\" (-1)\n",
            "Requirement already satisfied: openslide-python in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (1.1.1)\n",
            "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from openslide-python) (6.0.0)\n",
            "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\n",
            "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6CH8d5IQqXMY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2332
        },
        "outputId": "b38e520b-d41e-4a6e-806e-9cccd5f663dd"
      },
      "cell_type": "code",
      "source": [
        "#LOOP TO CROP WSI PER FOLDERS\n",
        "\n",
        "main_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf\"\n",
        "main_folders = [main_path + \"/Test\", main_path + \"/Training\", main_path + \"/Validation\"]\n",
        "\n",
        "for main_folder in main_folders:\n",
        "    new_path = main_folder\n",
        "    wsi_cropping(new_path)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Test/Healthy/\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Test/Healthy/\n",
            "======================================================\n",
            "Storage type:               disk\n",
            "Images directory:           /Users/Mac/Desktop/ROI-dataset-bioinf/Test/Healthy/\n",
            "Data store directory:       /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Test/Healthy/\n",
            "Images found:               8\n",
            "======================================================\n",
            "49_H_1.svs 49_H_2.svs 49_H_3.svs 49_H_4.svs 49_H_5.svs 49_H_6.svs 49_H_7.svs 49_H_8.svs \n",
            "============ Patches Dataset Stats ===========\n",
            "Total patches sampled:                     30\n",
            "Patches saved to:                          /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Test/Healthy/\n",
            "Patches saved with prefix:                 \n",
            "\n",
            "Time usage: 0:00:23\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Test/Benign/\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Test/Benign/\n",
            "======================================================\n",
            "Storage type:               disk\n",
            "Images directory:           /Users/Mac/Desktop/ROI-dataset-bioinf/Test/Benign/\n",
            "Data store directory:       /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Test/Benign/\n",
            "Images found:               3\n",
            "======================================================\n",
            "32_AD_1.svs 32_AD_2.svs 32_AD_3.svs \n",
            "============ Patches Dataset Stats ===========\n",
            "Total patches sampled:                     9\n",
            "Patches saved to:                          /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Test/Benign/\n",
            "Patches saved with prefix:                 \n",
            "\n",
            "Time usage: 0:00:10\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Test/Cancer/\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Test/Cancer/\n",
            "======================================================\n",
            "Storage type:               disk\n",
            "Images directory:           /Users/Mac/Desktop/ROI-dataset-bioinf/Test/Cancer/\n",
            "Data store directory:       /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Test/Cancer/\n",
            "Images found:               3\n",
            "======================================================\n",
            "40_AC_1.svs 40_AC_2.svs 40_AC_3.svs \n",
            "============ Patches Dataset Stats ===========\n",
            "Total patches sampled:                     9\n",
            "Patches saved to:                          /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Test/Cancer/\n",
            "Patches saved with prefix:                 \n",
            "\n",
            "Time usage: 0:00:07\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Training/Healthy/\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Training/Healthy/\n",
            "======================================================\n",
            "Storage type:               disk\n",
            "Images directory:           /Users/Mac/Desktop/ROI-dataset-bioinf/Training/Healthy/\n",
            "Data store directory:       /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Training/Healthy/\n",
            "Images found:               19\n",
            "======================================================\n",
            "18_H_1.svs 18_H_2.svs 18_H_3.svs 18_H_4.svs 20_H_1.svs 20_H_2.svs 20_H_3.svs 44_H_1.svs 44_H_2.svs 44_H_3.svs 46_H_1.svs 46_H_2.svs 46_H_3.svs 48_H_1.svs 48_H_2.svs 48_H_3.svs 7_H_1.svs 7_H_2.svs 7_H_3.svs \n",
            "============ Patches Dataset Stats ===========\n",
            "Total patches sampled:                     57\n",
            "Patches saved to:                          /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Training/Healthy/\n",
            "Patches saved with prefix:                 \n",
            "\n",
            "Time usage: 0:00:40\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Training/Benign/\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Training/Benign/\n",
            "======================================================\n",
            "Storage type:               disk\n",
            "Images directory:           /Users/Mac/Desktop/ROI-dataset-bioinf/Training/Benign/\n",
            "Data store directory:       /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Training/Benign/\n",
            "Images found:               18\n",
            "======================================================\n",
            "24_AD_1.svs 24_AD_2.svs 24_AD_3.svs 25_AD_1.svs 25_AD_2.svs 25_AD_3.svs 27_AD_1.svs 27_AD_2.svs 27_AD_3.svs 28_AD_1.svs 28_AD_2.svs 28_AD_3.svs 29_AD_1.svs 29_AD_2.svs 29_AD_3.svs 30_AD_1.svs 30_AD_2.svs 30_AD_3.svs \n",
            "============ Patches Dataset Stats ===========\n",
            "Total patches sampled:                     54\n",
            "Patches saved to:                          /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Training/Benign/\n",
            "Patches saved with prefix:                 \n",
            "\n",
            "Time usage: 0:00:35\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Training/Cancer/\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Training/Cancer/\n",
            "======================================================\n",
            "Storage type:               disk\n",
            "Images directory:           /Users/Mac/Desktop/ROI-dataset-bioinf/Training/Cancer/\n",
            "Data store directory:       /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Training/Cancer/\n",
            "Images found:               13\n",
            "======================================================\n",
            "12_AC_1.svs 12_AC_2.svs 15_AC_1.svs 15_AC_2.svs 16_AC_1.svs 16_AC_2.svs 16_AC_3.svs 21_AC_1.svs 21_AC_2.svs 2_AC_1.svs 2_AC_2.svs 6_AC_1.svs 6_AC_2.svs \n",
            "============ Patches Dataset Stats ===========\n",
            "Total patches sampled:                     39\n",
            "Patches saved to:                          /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Training/Cancer/\n",
            "Patches saved with prefix:                 \n",
            "\n",
            "Time usage: 0:00:26\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Healthy/\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Validation/Healthy/\n",
            "======================================================\n",
            "Storage type:               disk\n",
            "Images directory:           /Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Healthy/\n",
            "Data store directory:       /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Validation/Healthy/\n",
            "Images found:               15\n",
            "======================================================\n",
            "50_H_1.svs 50_H_2.svs 50_H_3.svs 50_H_4.svs 50_H_5.svs 50_H_6.svs 50_H_7.svs 55_H_1.svs 55_H_2.svs 55_H_3.svs 55_H_4.svs 55_H_5.svs 55_H_6.svs 55_H_7.svs 55_H_8.svs \n",
            "============ Patches Dataset Stats ===========\n",
            "Total patches sampled:                     60\n",
            "Patches saved to:                          /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Validation/Healthy/\n",
            "Patches saved with prefix:                 \n",
            "\n",
            "Time usage: 0:00:28\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Benign/\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Validation/Benign/\n",
            "======================================================\n",
            "Storage type:               disk\n",
            "Images directory:           /Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Benign/\n",
            "Data store directory:       /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Validation/Benign/\n",
            "Images found:               6\n",
            "======================================================\n",
            "38_AD_1.svs 38_AD_2.svs 38_AD_3.svs 42_AD_1.svs 42_AD_2.svs 42_AD_3.svs \n",
            "============ Patches Dataset Stats ===========\n",
            "Total patches sampled:                     18\n",
            "Patches saved to:                          /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Validation/Benign/\n",
            "Patches saved with prefix:                 \n",
            "\n",
            "Time usage: 0:00:13\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Cancer/\n",
            "/Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Validation/Cancer/\n",
            "======================================================\n",
            "Storage type:               disk\n",
            "Images directory:           /Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Cancer/\n",
            "Data store directory:       /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Validation/Cancer/\n",
            "Images found:               7\n",
            "======================================================\n",
            "41_AC_1.svs 41_AC_2.svs 41_AC_3.svs 43_AC_1.svs 43_AC_2.svs 43_AC_3.svs 43_AC_4.svs \n",
            "============ Patches Dataset Stats ===========\n",
            "Total patches sampled:                     21\n",
            "Patches saved to:                          /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset/Validation/Cancer/\n",
            "Patches saved with prefix:                 \n",
            "\n",
            "Time usage: 0:00:12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yseE6-5C-gxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee733aa0-50fe-482c-c1f9-845ee779dc84"
      },
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "p=Path(main_path)\n",
        "\n",
        "pezzi = p.parts\n",
        "pezzi[0] + pezzi[3] + pezzi[0] + pezzi[4]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/Desktop/ROI-dataset-bioinf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "XaISfS_fvzVz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**SCRIPT FOR ERASING ONLY WHITE IMAGES**"
      ]
    },
    {
      "metadata": {
        "id": "fuEFrnvMv5bi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#the function for deleting white patches\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def deleteWhite(path):                                              #path is the path of the Patches folder\n",
        "    \"\"\"Function that deletes all patches that are completely (or mostly) white.\"\"\"\n",
        "\n",
        "    folders = [path + \"/Healthy\", path + \"/Benign\", path + \"/Cancer\"]\n",
        "    for folder in folders:                                          #loops through the three folders of patches\n",
        "        count = 0\n",
        "        for filename in glob.glob(os.path.join(folder, '*.png')):   #sequentially selects each .png file in the current folder\n",
        "            img = cv2.imread(filename)\n",
        "            (x,y,z) = img.shape                                     #img.shap is 64 64 3\n",
        "            white = 0\n",
        "            for i in range(0,x):                                    #analyzes the image pixel by pixel\n",
        "                for j in range(0,y):\n",
        "                    pixel = img[i,j]\n",
        "                    b = pixel[0]\n",
        "                    g = pixel[1]\n",
        "                    r = pixel[2]\n",
        "                    if b == 255:                                    #if b,g,r are all 255 it means the pixel is white\n",
        "                    #if b == 211:   \n",
        "                      if g == 255:\n",
        "                      #if g == 211:\n",
        "                          if r == 255:\n",
        "                          #if r == 211:\n",
        "                                white = white + 1                   #I use white as a counter to keep track of the number of white pixels\n",
        "                    if white > 50:                                  #in the dataset that we have, an image having a few white pixels means it will be almost all white\n",
        "                        break                                       #thus to make the process a bit shorter I only count to 50 white pixels and then break the loop, since it is unneded to count further\n",
        "                if white > 50:\n",
        "                    break\n",
        "            if white > 50:                                          #if a patch is found to have many white pixels (which means it will be mostly white) I delete it from its folder\n",
        "                os.remove(filename)\n",
        "                count = count + 1\n",
        "        print(\"Deleted\",count,\"patches in\",folder)\n",
        "\n",
        "    return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b44RtPXH6tkR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b52b2b4b-cb55-408b-c963-2b85a64c3647"
      },
      "cell_type": "code",
      "source": [
        "#LOOP TO CLEAN UP FOLDERS\n",
        "\n",
        "#main_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset\"\n",
        "main_path='/Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset'\n",
        "main_folders = [main_path + \"/Test\", main_path + \"/Training\", main_path + \"/Validation\"]\n",
        "for main_folder in main_folders:\n",
        "    new_path = main_folder\n",
        "    deleteWhite(new_path)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deleted 8 patches in /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset//Test/Healthy\n",
            "Deleted 4 patches in /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset//Test/Benign\n",
            "Deleted 6 patches in /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset//Test/Cancer\n",
            "Deleted 34 patches in /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset//Training/Healthy\n",
            "Deleted 30 patches in /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset//Training/Benign\n",
            "Deleted 20 patches in /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset//Training/Cancer\n",
            "Deleted 20 patches in /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset//Validation/Healthy\n",
            "Deleted 8 patches in /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset//Validation/Benign\n",
            "Deleted 10 patches in /Users/Mac/Desktop/ROI-dataset-bioinf/Img_Dataset//Validation/Cancer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eiShUK7CtamG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CNN BASE**"
      ]
    },
    {
      "metadata": {
        "id": "g3BQ4dD9unk5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "106d04a0-0f65-4665-934a-9ef77fab2ffb"
      },
      "cell_type": "code",
      "source": [
        "#CNN BASE MODEL - DATA LOADING\n",
        "\n",
        "import numpy as np\n",
        "!pip3 install keras\n",
        "#!pip3 install tensorflow==1.5.0\n",
        "!pip3 install tensorflow\n",
        "!pip install mxnet-mkl\n",
        "!pip3 install sklearn\n",
        "!pip3 install keras_tqdm\n",
        "!pip install scipy\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import *\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.2.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.9.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: mxnet-mkl in /usr/local/lib/python3.6/dist-packages (1.4.0.post0)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (1.14.6)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (1.24.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2.8)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.2.1)\n",
            "Requirement already satisfied: keras_tqdm in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (2.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (4.28.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.2.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.14.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NaQkjeNR7MnV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Training/Patches\"\n",
        "#train_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Training/Patches/\"\n",
        "valid_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Validation/Patches\"\n",
        "#valid_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Patches\"\n",
        "#test_path =\"/Users/Mac/Desktop/ROI-dataset-bioinf/Test/Patches\"\n",
        "test_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Test/Patches\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UzyWGHvlC_Fb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)\n",
        "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)\n",
        "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5RLPLu5mmhGj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For plotting images with labels\n",
        "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NyJOfCvIVQWS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imgs, labels = next(train_batches)\n",
        "\n",
        "#plots(imgs,titles=labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QBTKs_NaVR86",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CNN MODEL BUILDING\n",
        "model = Sequential([Conv2D(32,(3,3),activation='relu',input_shape=(64,64,3)), Flatten(), Dense(3, activation='softmax'),])\n",
        "model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit_generator(train_batches, steps_per_epoch=22, validation_data=valid_batches, validation_steps=22, epochs=5, verbose=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97pjhfx3WmVq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_imgs, test_labels = next(test_batches)\n",
        "plots(test_imgs, titles = test_labels)\n",
        "#test_labels = test_labels[:,0]\n",
        "test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DMrMcizcaTrF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict_generator(test_batches, steps=1, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ze9ZQv93dGX0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sMFD6PUqdIHM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -U scikit-learn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(test_labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yB1x83jJb8N8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#MULTI-LABEL CONFUSION MATRIX\n",
        "\n",
        "y_test_non_category = [ np.argmax(t) for t in test_labels ]\n",
        "y_predict_non_category = [ np.argmax(t) for t in predictions ]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(y_test_non_category, y_predict_non_category)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f-e8J4TceQl-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "#This function prints and plots the confusion matrix.\n",
        "#Normalization can ben applied by setting 'normalize-True'\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks=np.arange(len(classes))\n",
        "    plt.xticks(tick_marks,classes,rotation=45)\n",
        "    plt.yticks(tick_marks,classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2\n",
        "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "           plt.text(j, i, \"{:0.2f}\".format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "        else:\n",
        "           plt.text(j, i, format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RzLMUdm-keV_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm_plot_labels = ['Benign','Healthy','Cancer']\n",
        "plot_confusion_matrix(conf_mat, cm_plot_labels,title ='Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kPrSiv3lmHC3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**FIN QUI TUTTO OK, IL MODELLO FA SCHIFO MA TECNICAMENTE FA QUELLO CHE DEVE FARE, SE LA CONFUSION MATRIX È GIUSTA, HO TROVATO COME PLOTTARLA CON UN MODELLO A MULTI LABEL**"
      ]
    },
    {
      "metadata": {
        "id": "dH8ZmCrhtf1j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**FINE TUNING OF VGG16** "
      ]
    },
    {
      "metadata": {
        "id": "024xq-WbmSqU",
        "colab_type": "code",
        "outputId": "db2debc4-e461-47b3-de47-64ef08af5127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "cell_type": "code",
      "source": [
        "#FINE TUNING OF A PRE-TRAINED MODEL (VGG16)\n",
        "\n",
        "import numpy as np\n",
        "!pip3 install keras\n",
        "#!pip3 install tensorflow==1.5.0\n",
        "!pip3 install tensorflow\n",
        "!pip install mxnet-mkl\n",
        "!pip3 install sklearn\n",
        "!pip3 install keras_tqdm\n",
        "!pip install scipy\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import *\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "vgg16_model = keras.applications.vgg16.VGG16()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.9)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.9.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: mxnet-mkl in /usr/local/lib/python3.6/dist-packages (1.4.0.post0)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (2.21.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (0.8.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (1.24.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2.8)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n",
            "Requirement already satisfied: keras_tqdm in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (4.28.1)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (2.2.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.2.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.14.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LKxIhkFQpEoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg16_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e0LtghsxzICS",
        "colab_type": "code",
        "outputId": "0b44aa97-ec99-4e57-aa9b-b445aed27c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "train_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Training/Patches\"\n",
        "#train_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Training/Patches/\"\n",
        "valid_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Validation/Patches\"\n",
        "#valid_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Patches\"\n",
        "#test_path =\"/Users/Mac/Desktop/ROI-dataset-bioinf/Test/Patches\"\n",
        "test_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Test/Patches\"\n",
        "\n",
        "#FATTO DA CHIARA QUESTO AUGMENT?\n",
        "gen = ImageDataGenerator(rotation_range=10, shear_range=0.15, channel_shift_range=10., horizontal_flip=True)\n",
        "\n",
        "train_batches = gen.flow_from_directory(train_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=100)\n",
        "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=100)\n",
        "test_batches = ImageDataGenerator().flow_from_directory(test_path, shuffle=False, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=100)\n",
        "\n",
        "#added shuffle=False for test_batches"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2263 images belonging to 3 classes.\n",
            "Found 1053 images belonging to 3 classes.\n",
            "Found 437 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0rV5hG5K1ftf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(vgg16_model)\n",
        "#create a Sequential model in which we add all the layers of the VGG16 model\n",
        "model = Sequential()\n",
        "for layer in vgg16_model.layers[:-1]:\n",
        "  #all layers except for the last one which is the predictions layers we don't want\n",
        "    model.add(layer)\n",
        "    \n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e_uGdPHX2kX9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JI2uQhG_Cfiv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95lCz-aEDjZc",
        "colab_type": "code",
        "outputId": "6b99e42e-4d7f-4d8f-8744-8f78e6e3229b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3434
        }
      },
      "cell_type": "code",
      "source": [
        "#TRAIN THE VGG16 MODEL\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=2,\n",
        "                              verbose=0, mode='auto')\n",
        "\n",
        "#TRY TO COMPILE WITH SGD OPTIMIZER AND DEFINE MOMENTUM, TRY TO RUN LONGER EPOCHS, TRY TO TAKE BIGGER BATCHES\n",
        "\n",
        "#steps per epoch and validation step = dataset size / batch size\n",
        "#keras.optimizers.SGD(lr=0.1, momentum=0.0, decay=0.0, nesterov=False)\n",
        "#Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(SGD(lr=0.0001, momentum=0.9, decay=0.0, nesterov=True), loss ='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit_generator(train_batches, steps_per_epoch=train_batches.samples/train_batches.batch_size, validation_data=valid_batches, validation_steps=valid_batches.samples/valid_batches.batch_size, epochs=100, verbose=2)#, callbacks=[es])\n",
        "#model.save('/content/gdrive/My Drive/Bioinformatica/FirstVGG16.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " - 45s - loss: 0.0868 - acc: 0.9694 - val_loss: 0.5176 - val_acc: 0.7882\n",
            "Epoch 2/100\n",
            " - 23s - loss: 0.0901 - acc: 0.9704 - val_loss: 0.6044 - val_acc: 0.7635\n",
            "Epoch 3/100\n",
            " - 28s - loss: 0.0923 - acc: 0.9671 - val_loss: 0.5375 - val_acc: 0.7816\n",
            "Epoch 4/100\n",
            " - 29s - loss: 0.0941 - acc: 0.9695 - val_loss: 0.5534 - val_acc: 0.7768\n",
            "Epoch 5/100\n",
            " - 28s - loss: 0.0920 - acc: 0.9686 - val_loss: 0.5387 - val_acc: 0.7787\n",
            "Epoch 6/100\n",
            " - 28s - loss: 0.0879 - acc: 0.9736 - val_loss: 0.5942 - val_acc: 0.7673\n",
            "Epoch 7/100\n",
            " - 29s - loss: 0.0862 - acc: 0.9726 - val_loss: 0.5408 - val_acc: 0.7797\n",
            "Epoch 8/100\n",
            " - 30s - loss: 0.0858 - acc: 0.9695 - val_loss: 0.5561 - val_acc: 0.7768\n",
            "Epoch 9/100\n",
            " - 28s - loss: 0.0834 - acc: 0.9760 - val_loss: 0.5568 - val_acc: 0.7768\n",
            "Epoch 10/100\n",
            " - 29s - loss: 0.0840 - acc: 0.9732 - val_loss: 0.5482 - val_acc: 0.7797\n",
            "Epoch 11/100\n",
            " - 28s - loss: 0.0829 - acc: 0.9723 - val_loss: 0.5557 - val_acc: 0.7759\n",
            "Epoch 12/100\n",
            " - 28s - loss: 0.0847 - acc: 0.9728 - val_loss: 0.5556 - val_acc: 0.7768\n",
            "Epoch 13/100\n",
            " - 30s - loss: 0.0934 - acc: 0.9673 - val_loss: 0.5885 - val_acc: 0.7702\n",
            "Epoch 14/100\n",
            " - 28s - loss: 0.0878 - acc: 0.9721 - val_loss: 0.5247 - val_acc: 0.7873\n",
            "Epoch 15/100\n",
            " - 28s - loss: 0.0873 - acc: 0.9726 - val_loss: 0.5630 - val_acc: 0.7768\n",
            "Epoch 16/100\n",
            " - 29s - loss: 0.0814 - acc: 0.9717 - val_loss: 0.5194 - val_acc: 0.7911\n",
            "Epoch 17/100\n",
            " - 28s - loss: 0.0905 - acc: 0.9684 - val_loss: 0.5561 - val_acc: 0.7825\n",
            "Epoch 18/100\n",
            " - 28s - loss: 0.0834 - acc: 0.9708 - val_loss: 0.5728 - val_acc: 0.7778\n",
            "Epoch 19/100\n",
            " - 30s - loss: 0.0857 - acc: 0.9730 - val_loss: 0.5807 - val_acc: 0.7759\n",
            "Epoch 20/100\n",
            " - 28s - loss: 0.0839 - acc: 0.9725 - val_loss: 0.5641 - val_acc: 0.7778\n",
            "Epoch 21/100\n",
            " - 29s - loss: 0.0942 - acc: 0.9682 - val_loss: 0.5659 - val_acc: 0.7778\n",
            "Epoch 22/100\n",
            " - 28s - loss: 0.0900 - acc: 0.9713 - val_loss: 0.5790 - val_acc: 0.7711\n",
            "Epoch 23/100\n",
            " - 28s - loss: 0.0834 - acc: 0.9721 - val_loss: 0.5758 - val_acc: 0.7702\n",
            "Epoch 24/100\n",
            " - 30s - loss: 0.0833 - acc: 0.9756 - val_loss: 0.5719 - val_acc: 0.7740\n",
            "Epoch 25/100\n",
            " - 28s - loss: 0.0896 - acc: 0.9671 - val_loss: 0.5729 - val_acc: 0.7749\n",
            "Epoch 26/100\n",
            " - 27s - loss: 0.0843 - acc: 0.9697 - val_loss: 0.5914 - val_acc: 0.7692\n",
            "Epoch 27/100\n",
            " - 29s - loss: 0.0920 - acc: 0.9694 - val_loss: 0.5526 - val_acc: 0.7835\n",
            "Epoch 28/100\n",
            " - 28s - loss: 0.0889 - acc: 0.9732 - val_loss: 0.5934 - val_acc: 0.7692\n",
            "Epoch 29/100\n",
            " - 28s - loss: 0.0832 - acc: 0.9710 - val_loss: 0.5705 - val_acc: 0.7740\n",
            "Epoch 30/100\n",
            " - 31s - loss: 0.0903 - acc: 0.9671 - val_loss: 0.5744 - val_acc: 0.7730\n",
            "Epoch 31/100\n",
            " - 28s - loss: 0.0921 - acc: 0.9660 - val_loss: 0.5919 - val_acc: 0.7711\n",
            "Epoch 32/100\n",
            " - 28s - loss: 0.0853 - acc: 0.9726 - val_loss: 0.6023 - val_acc: 0.7645\n",
            "Epoch 33/100\n",
            " - 29s - loss: 0.0856 - acc: 0.9722 - val_loss: 0.6130 - val_acc: 0.7645\n",
            "Epoch 34/100\n",
            " - 28s - loss: 0.0877 - acc: 0.9745 - val_loss: 0.5427 - val_acc: 0.7844\n",
            "Epoch 35/100\n",
            " - 29s - loss: 0.0910 - acc: 0.9692 - val_loss: 0.5887 - val_acc: 0.7692\n",
            "Epoch 36/100\n",
            " - 28s - loss: 0.0894 - acc: 0.9695 - val_loss: 0.5354 - val_acc: 0.7854\n",
            "Epoch 37/100\n",
            " - 28s - loss: 0.0783 - acc: 0.9789 - val_loss: 0.5703 - val_acc: 0.7778\n",
            "Epoch 38/100\n",
            " - 29s - loss: 0.0853 - acc: 0.9714 - val_loss: 0.5405 - val_acc: 0.7844\n",
            "Epoch 39/100\n",
            " - 28s - loss: 0.0808 - acc: 0.9727 - val_loss: 0.5695 - val_acc: 0.7778\n",
            "Epoch 40/100\n",
            " - 28s - loss: 0.0832 - acc: 0.9736 - val_loss: 0.5508 - val_acc: 0.7825\n",
            "Epoch 41/100\n",
            " - 30s - loss: 0.0898 - acc: 0.9675 - val_loss: 0.5615 - val_acc: 0.7816\n",
            "Epoch 42/100\n",
            " - 28s - loss: 0.0852 - acc: 0.9687 - val_loss: 0.5575 - val_acc: 0.7806\n",
            "Epoch 43/100\n",
            " - 28s - loss: 0.0804 - acc: 0.9717 - val_loss: 0.5214 - val_acc: 0.7892\n",
            "Epoch 44/100\n",
            " - 29s - loss: 0.0836 - acc: 0.9725 - val_loss: 0.5498 - val_acc: 0.7835\n",
            "Epoch 45/100\n",
            " - 28s - loss: 0.0811 - acc: 0.9758 - val_loss: 0.5377 - val_acc: 0.7854\n",
            "Epoch 46/100\n",
            " - 28s - loss: 0.0788 - acc: 0.9743 - val_loss: 0.5558 - val_acc: 0.7797\n",
            "Epoch 47/100\n",
            " - 29s - loss: 0.0878 - acc: 0.9684 - val_loss: 0.5682 - val_acc: 0.7778\n",
            "Epoch 48/100\n",
            " - 28s - loss: 0.0850 - acc: 0.9734 - val_loss: 0.5700 - val_acc: 0.7768\n",
            "Epoch 49/100\n",
            " - 28s - loss: 0.0840 - acc: 0.9719 - val_loss: 0.5612 - val_acc: 0.7797\n",
            "Epoch 50/100\n",
            " - 29s - loss: 0.0867 - acc: 0.9691 - val_loss: 0.5810 - val_acc: 0.7740\n",
            "Epoch 51/100\n",
            " - 28s - loss: 0.0885 - acc: 0.9719 - val_loss: 0.5791 - val_acc: 0.7768\n",
            "Epoch 52/100\n",
            " - 30s - loss: 0.0865 - acc: 0.9730 - val_loss: 0.5463 - val_acc: 0.7854\n",
            "Epoch 53/100\n",
            " - 28s - loss: 0.0888 - acc: 0.9679 - val_loss: 0.5686 - val_acc: 0.7797\n",
            "Epoch 54/100\n",
            " - 28s - loss: 0.0829 - acc: 0.9737 - val_loss: 0.5620 - val_acc: 0.7825\n",
            "Epoch 55/100\n",
            " - 29s - loss: 0.0896 - acc: 0.9697 - val_loss: 0.5633 - val_acc: 0.7797\n",
            "Epoch 56/100\n",
            " - 29s - loss: 0.0818 - acc: 0.9710 - val_loss: 0.5481 - val_acc: 0.7825\n",
            "Epoch 57/100\n",
            " - 28s - loss: 0.0829 - acc: 0.9717 - val_loss: 0.5495 - val_acc: 0.7844\n",
            "Epoch 58/100\n",
            " - 29s - loss: 0.0872 - acc: 0.9722 - val_loss: 0.5016 - val_acc: 0.7996\n",
            "Epoch 59/100\n",
            " - 27s - loss: 0.0858 - acc: 0.9731 - val_loss: 0.5589 - val_acc: 0.7787\n",
            "Epoch 60/100\n",
            " - 28s - loss: 0.0801 - acc: 0.9756 - val_loss: 0.5897 - val_acc: 0.7740\n",
            "Epoch 61/100\n",
            " - 29s - loss: 0.0849 - acc: 0.9737 - val_loss: 0.5474 - val_acc: 0.7854\n",
            "Epoch 62/100\n",
            " - 27s - loss: 0.0824 - acc: 0.9734 - val_loss: 0.5497 - val_acc: 0.7825\n",
            "Epoch 63/100\n",
            " - 30s - loss: 0.0759 - acc: 0.9797 - val_loss: 0.5407 - val_acc: 0.7854\n",
            "Epoch 64/100\n",
            " - 29s - loss: 0.0758 - acc: 0.9776 - val_loss: 0.5483 - val_acc: 0.7854\n",
            "Epoch 65/100\n",
            " - 28s - loss: 0.0811 - acc: 0.9717 - val_loss: 0.5594 - val_acc: 0.7835\n",
            "Epoch 66/100\n",
            " - 28s - loss: 0.0808 - acc: 0.9741 - val_loss: 0.5455 - val_acc: 0.7844\n",
            "Epoch 67/100\n",
            " - 30s - loss: 0.0797 - acc: 0.9743 - val_loss: 0.5633 - val_acc: 0.7778\n",
            "Epoch 68/100\n",
            " - 28s - loss: 0.0853 - acc: 0.9723 - val_loss: 0.5626 - val_acc: 0.7806\n",
            "Epoch 69/100\n",
            " - 29s - loss: 0.0846 - acc: 0.9730 - val_loss: 0.5788 - val_acc: 0.7721\n",
            "Epoch 70/100\n",
            " - 28s - loss: 0.0823 - acc: 0.9721 - val_loss: 0.5539 - val_acc: 0.7825\n",
            "Epoch 71/100\n",
            " - 28s - loss: 0.0852 - acc: 0.9749 - val_loss: 0.5555 - val_acc: 0.7816\n",
            "Epoch 72/100\n",
            " - 29s - loss: 0.0843 - acc: 0.9714 - val_loss: 0.5745 - val_acc: 0.7768\n",
            "Epoch 73/100\n",
            " - 27s - loss: 0.0806 - acc: 0.9716 - val_loss: 0.5937 - val_acc: 0.7664\n",
            "Epoch 74/100\n",
            " - 29s - loss: 0.0828 - acc: 0.9752 - val_loss: 0.5566 - val_acc: 0.7787\n",
            "Epoch 75/100\n",
            " - 29s - loss: 0.0823 - acc: 0.9726 - val_loss: 0.5939 - val_acc: 0.7673\n",
            "Epoch 76/100\n",
            " - 28s - loss: 0.0789 - acc: 0.9756 - val_loss: 0.5975 - val_acc: 0.7664\n",
            "Epoch 77/100\n",
            " - 28s - loss: 0.0792 - acc: 0.9727 - val_loss: 0.5553 - val_acc: 0.7797\n",
            "Epoch 78/100\n",
            " - 29s - loss: 0.0749 - acc: 0.9765 - val_loss: 0.5539 - val_acc: 0.7806\n",
            "Epoch 79/100\n",
            " - 28s - loss: 0.0787 - acc: 0.9753 - val_loss: 0.5488 - val_acc: 0.7816\n",
            "Epoch 80/100\n",
            " - 28s - loss: 0.0791 - acc: 0.9765 - val_loss: 0.5630 - val_acc: 0.7797\n",
            "Epoch 81/100\n",
            " - 29s - loss: 0.0755 - acc: 0.9749 - val_loss: 0.5718 - val_acc: 0.7749\n",
            "Epoch 82/100\n",
            " - 28s - loss: 0.0813 - acc: 0.9730 - val_loss: 0.5815 - val_acc: 0.7749\n",
            "Epoch 83/100\n",
            " - 28s - loss: 0.0771 - acc: 0.9760 - val_loss: 0.5676 - val_acc: 0.7797\n",
            "Epoch 84/100\n",
            " - 29s - loss: 0.0792 - acc: 0.9730 - val_loss: 0.5762 - val_acc: 0.7759\n",
            "Epoch 85/100\n",
            " - 29s - loss: 0.0762 - acc: 0.9778 - val_loss: 0.5688 - val_acc: 0.7778\n",
            "Epoch 86/100\n",
            " - 29s - loss: 0.0795 - acc: 0.9760 - val_loss: 0.5678 - val_acc: 0.7787\n",
            "Epoch 87/100\n",
            " - 28s - loss: 0.0748 - acc: 0.9769 - val_loss: 0.5368 - val_acc: 0.7863\n",
            "Epoch 88/100\n",
            " - 29s - loss: 0.0810 - acc: 0.9750 - val_loss: 0.5596 - val_acc: 0.7787\n",
            "Epoch 89/100\n",
            " - 29s - loss: 0.0812 - acc: 0.9743 - val_loss: 0.5523 - val_acc: 0.7806\n",
            "Epoch 90/100\n",
            " - 28s - loss: 0.0793 - acc: 0.9750 - val_loss: 0.5926 - val_acc: 0.7692\n",
            "Epoch 91/100\n",
            " - 27s - loss: 0.0861 - acc: 0.9684 - val_loss: 0.6112 - val_acc: 0.7635\n",
            "Epoch 92/100\n",
            " - 29s - loss: 0.0791 - acc: 0.9786 - val_loss: 0.5709 - val_acc: 0.7778\n",
            "Epoch 93/100\n",
            " - 28s - loss: 0.0760 - acc: 0.9735 - val_loss: 0.5574 - val_acc: 0.7816\n",
            "Epoch 94/100\n",
            " - 27s - loss: 0.0710 - acc: 0.9771 - val_loss: 0.5312 - val_acc: 0.7892\n",
            "Epoch 95/100\n",
            " - 29s - loss: 0.0854 - acc: 0.9704 - val_loss: 0.5485 - val_acc: 0.7816\n",
            "Epoch 96/100\n",
            " - 29s - loss: 0.0737 - acc: 0.9769 - val_loss: 0.5879 - val_acc: 0.7702\n",
            "Epoch 97/100\n",
            " - 28s - loss: 0.0808 - acc: 0.9730 - val_loss: 0.5424 - val_acc: 0.7854\n",
            "Epoch 98/100\n",
            " - 29s - loss: 0.0827 - acc: 0.9745 - val_loss: 0.5171 - val_acc: 0.7930\n",
            "Epoch 99/100\n",
            " - 28s - loss: 0.0834 - acc: 0.9723 - val_loss: 0.5960 - val_acc: 0.7711\n",
            "Epoch 100/100\n",
            " - 28s - loss: 0.0756 - acc: 0.9778 - val_loss: 0.5506 - val_acc: 0.7854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a41262e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "PQdWmv2En-Rj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**BEST PARAMETERS SEARCH** (si va beh per fare questo dovrei avere y_train come vettore di label perché è il target)"
      ]
    },
    {
      "metadata": {
        "id": "C4I4pxIpnVmW",
        "colab_type": "code",
        "outputId": "83f3a645-fa06-4dd6-aac4-9e537a62ee32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "def make_classifier(optimizer):\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(6, kernel_initializer = 'uniform', activation = 'relu', input_dim=11))\n",
        "    classifier.add(Dense(6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer= optimizer,loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "    return classifier\n",
        "  \n",
        "classifier = KerasClassifier(build_fn = make_classifier)\n",
        "\n",
        "params = {\n",
        "    'batch_size':[32,100],\n",
        "    'nb_epoch':[30,100],\n",
        "    'optimizer':['adam','sgd']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=classifier,\n",
        "                           param_grid=params,\n",
        "                           scoring='accuracy',\n",
        "                           cv=10)\n",
        "train_batches = gen.flow_from_directory(train_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=1)\n",
        "grid_search = grid_search.fit(train_batches,train_batches.classes)\n",
        "\n",
        "best_param = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2263 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-c8f29fb94166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                            cv=10)\n\u001b[1;32m     24\u001b[0m \u001b[0mtrain_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Benign'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Healthy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cancer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mbest_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'ndim'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Pw21Fbc0HlpT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/My Drive/Bioinformatica/FirstVGG16.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16yYjozTaS3Q",
        "colab_type": "code",
        "outputId": "b2b712ef-4b9d-409b-a901-85b3944655cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#steps = images in the test folder / batch size\n",
        "\n",
        "predictions = model.predict_generator(test_batches, steps= 5, verbose=1)\n",
        "\n",
        "#predictions = np.argmax(predictions, axis=-1) #multiple categories"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 513ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IevjxPbdz42F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "#This function prints and plots the confusion matrix.\n",
        "#Normalization can ben applied by setting 'normalize-True'\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks=np.arange(len(classes))\n",
        "    plt.xticks(tick_marks,classes,rotation=45)\n",
        "    plt.yticks(tick_marks,classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2\n",
        "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "           plt.text(j, i, \"{:0.2f}\".format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "        else:\n",
        "           plt.text(j, i, format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lXWPqShJahcX",
        "colab_type": "code",
        "outputId": "5c3ab2ec-d269-42e4-91cd-54b90262a521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -U scikit-learn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#test_imgs, test_labels = next(test_batches)\n",
        "test_labels=test_batches.classes\n",
        "\n",
        "#MULTI-LABEL CONFUSION MATRIX\n",
        "\n",
        "y_test_non_category = [ np.argmax(t) for t in test_labels ]\n",
        "#y_test_non_category = np.argmax(test_labels, axis=-1) #multiple categories\n",
        "y_predict_non_category = [ np.argmax(t) for t in predictions ]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(y_test_non_category, y_predict_non_category)\n",
        "\n",
        "cm_plot_labels = ['Benign','Healthy','Cancer']\n",
        "plot_confusion_matrix(conf_mat,cm_plot_labels,normalize=False,title ='Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.20.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.2.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.14.6)\n",
            "Confusion matrix, without normalization\n",
            "[[242 159  36]\n",
            " [  0   0   0]\n",
            " [  0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAEmCAYAAAA9eGh/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5hl4i2DAMLq0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**ANOTHER WAY TO PREDICT AND PLOT THE CONFUSION MATRIX**"
      ]
    },
    {
      "metadata": {
        "id": "Kv4xTqC0Lmld",
        "colab_type": "code",
        "outputId": "6500b317-a767-4d96-a716-3e4389b335ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#from keras.models import load_model\n",
        "#model = load_model('/content/gdrive/My Drive/Bioinformatica/FirstVGG16.h5')\n",
        "\n",
        "generator = ImageDataGenerator().flow_from_directory(\n",
        "        '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Test/Patches',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=200)\n",
        "\n",
        "probabilities = model.predict_generator(generator, 1)\n",
        "#probabilities = np.argmax(probabilities, axis=-1) #multiple categories"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 437 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oImJd6lZeHIx",
        "colab_type": "code",
        "outputId": "a592228b-9ad8-48f5-a503-0018ad27cfe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -U scikit-learn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#cm = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "#MULTI-LABEL CONFUSION MATRIX\n",
        "test_dir, test_labels = next(generator)\n",
        "test_img = [ np.argmax(t) for t in test_labels ]\n",
        "predicted_img = [ np.argmax(t) for t in probabilities ]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(test_img, predicted_img)\n",
        "\n",
        "cm_plot_labels = ['Benign','Healthy','Cancer']\n",
        "plot_confusion_matrix(conf_mat,cm_plot_labels,normalize=True,title ='Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.20.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.2.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.14.6)\n",
            "Normalized confusion matrix\n",
            "[[0.58461538 0.32307692 0.09230769]\n",
            " [0.59722222 0.34722222 0.05555556]\n",
            " [0.53968254 0.33333333 0.12698413]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEmCAYAAADmw8JdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCfCg6ZxzCfCg6ZxzCfh/VLY7HeQuu6wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ebt5IeUAbJGI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**QUESTA DOVREBBE ESSERE LA FINE DELLA PRIMA PARTE DI TEST, SE FIN QUI I RISULTATI SONO BUONI, POSSIAMO FERMARCI SE NO BISOGNA FARE DATA AUGMENTATION E AUMENTARE LE EPOCHS**"
      ]
    },
    {
      "metadata": {
        "id": "K8dBilwSbHUR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#DATA AUGMENATION\n",
        "\n",
        "#NOTE: every time this script is run, image crops will augment of a 6 factor\n",
        "\n",
        "gen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, channel_shift_range=10., horizontal_flip=True)\n",
        "\n",
        "path=\"/content/gdrive/My Drive/Bioinformatica/Patches\"\n",
        "\n",
        "folders = [path + \"/Healthy\", path + \"/Benign\", path + \"/Cancer\"]\n",
        "for folder in folders:                                          #loops through the three folders of patches\n",
        "   for filename in glob.glob(os.path.join(folder, '*.png')):   #sequentially selects each .png file in the current folder\n",
        "      print(filename)\n",
        "      image = np.expand_dims(ndimage.imread(filename),0)\n",
        "      aug_iter = gen.flow(image)\n",
        "      aug_image = [next(aug_iter)[0].astype(np.uint8) for i in range(6)]  #get 6 samples of augmented images\n",
        "      for i in range(len(aug_image)):                                     #save all the generated images\n",
        "        scipy.misc.imsave(filename[:-4] + str(i) + '.png', aug_image[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDHtej_pRtX3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plots(aug_images, figsize=(20,7), rows=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9gMCxAa6Pky9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**SE I RISULTATI OTTENUTI CON UN DETERMINATO SET DI IMPOSTAZIONI SONO BUONI E VOGLIAMO FREEZZARLI E RIPRODURLI ...**"
      ]
    },
    {
      "metadata": {
        "id": "Wf1Il5dSPwvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as rn\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "#Setting the seed for numpy-generated random numbers\n",
        "np.random.seed(37)\n",
        "\n",
        "#Setting the seed for Python random numbers\n",
        "rn.seed(1254)\n",
        "\n",
        "#Setting the seed for Tensorflow random numbers\n",
        "tf.set_random_seed(89)\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "#Force TensorFlow to use a single thread\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "#Paste training Keras code here after setting the random seeds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hzocYylhSBvu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **CLASS ACTIVION MAP**"
      ]
    },
    {
      "metadata": {
        "id": "_u4vOjUh_zfO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# --- CLASS ACTIVATION MAP --- #\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "import keras.backend as K\n",
        "#from model import *\n",
        "#from data import *\n",
        "import cv2\n",
        "\n",
        "#After the last convolutional layer in a typical network like VGG16, we have an N-dimensional image, where N is the number of filters in this layer. \n",
        "#For example in VGG16, the last convolutional layer has 512 filters. For example, for an 1024x1024 input image (lets discard the fully connected layers, \n",
        "#so we can use any input image size we want), the output shape of the last convolutional layer will be 512x64x64. \n",
        "#Since 1024/64 = 16, we have a 16x16 spatial mapping resolution. \n",
        "#A global average pooling (GAP) layer just takes each of these 512 channels, and returns their spatial average. \n",
        "#Channels with high activations, will have high signals.\n",
        "\n",
        "def global_average_pooling(x):\n",
        "        return K.mean(x, axis = (2, 3))\n",
        "  \n",
        "\n",
        "def global_average_pooling_shape(input_shape):\n",
        "        return input_shape[0:2]\n",
        "  \n",
        "#The second step is to assign a weight to each output from the global average pooling layer, for each of the categories. \n",
        "#This can be done by adding a dense linear layer + softmax, training an SVM on the GAP output, or applying any other linear classifier on top of the GAP. \n",
        "#These weights set the importance of each of the convolutional layer outputs.\n",
        "\n",
        "\n",
        "#TO DO: \n",
        "#    --- definire una funzione che crei il modello VGG16 (ho visto che Elena ha creato il modello ma non dentro una funzione)\n",
        "def get_model():\n",
        "\t    model = VGG16_convolutions()\n",
        "\t    model = load_model_weights(model, \"vgg16_weights.h5\")\n",
        "\t    \n",
        "\t    model.add(Lambda(global_average_pooling, \n",
        "\t              output_shape=global_average_pooling_shape))\n",
        "\t    model.add(Dense(2, activation = 'softmax', init='uniform'))\n",
        "\t    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.5, nesterov=True)\n",
        "\t    model.compile(loss = 'categorical_crossentropy', \\\n",
        "            optimizer = sgd, metrics=['accuracy'])\n",
        "\t    return model\n",
        "\n",
        "def load_model_weights(model, weights_path):\n",
        "    print ('Loading model.')\n",
        "    f = h5py.File(weights_path)\n",
        "    for k in range(f.attrs['nb_layers']):\n",
        "        if k >= len(model.layers):\n",
        "            # we don't look at the last (fully-connected) layers in the savefile\n",
        "            break\n",
        "        g = f['layer_{}'.format(k)]\n",
        "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
        "        model.layers[k].set_weights(weights)\n",
        "        model.layers[k].trainable = False\n",
        "    f.close()\n",
        "    print ('Model loaded.')\n",
        "    return model\n",
        "\n",
        "def get_output_layer(model, layer_name):\n",
        "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "    layer = layer_dict[layer_name]\n",
        "    return layer    \n",
        "       \n",
        "#TO DO: \n",
        "# --- definire il \"dataset_path\"\n",
        "# --- definire la funzione \"load_images\": è necessario creare due path diversi, uno per immagini positive e l'altro per quelle negative\n",
        "#     (poi la faccio io appena riusciamo a fare i test)\n",
        "\n",
        "def train(dataset_path):\n",
        "        model = get_model()\n",
        "        X, y = load_images(dataset_path)\n",
        "\t      #print ('Training')\n",
        "        checkpoint_path=\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
        "        checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto')\n",
        "        model.fit(X, y, nb_epoch=40, batch_size=32, validation_split=0.2, verbose=1, callbacks=[checkpoint])\n",
        "\n",
        "#Now to create a heatmap for a class we can just take output images from the last convolutional layer, multiply them by their assigned weights \n",
        "#(different weights for each class), and sum.\n",
        "\n",
        "def visualize_class_activation_map(model_path, img_path, output_path):\n",
        "        model = load_model(model_path)\n",
        "        original_img = cv2.imread(img_path, 1)\n",
        "        width, height, _ = original_img.shape\n",
        "\n",
        "        #Reshape to the network input shape (3, w, h).\n",
        "        img = np.array([np.transpose(np.float32(original_img), (2, 0, 1))])\n",
        "        \n",
        "        #Get the 512 input weights to the softmax.\n",
        "        class_weights = model.layers[-1].get_weights()[0]\n",
        "        final_conv_layer = get_output_layer(model, \"conv5_3\")\n",
        "        get_output = K.function([model.layers[0].input], \\\n",
        "                    [final_conv_layer.output, \n",
        "        model.layers[-1].output])\n",
        "        [conv_outputs, predictions] = get_output([img])\n",
        "        conv_outputs = conv_outputs[0, :, :, :]\n",
        "\n",
        "        #Create the class activation map.\n",
        "        cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])\n",
        "        target_class = 1\n",
        "        for i, w in enumerate(class_weights[:, target_class]):\n",
        "                cam += w * conv_outputs[i, :, :]\n",
        "        print (\"predictions\"), predictions\n",
        "        cam /= np.max(cam)\n",
        "        cam = cv2.resize(cam, (height, width))\n",
        "        heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
        "        heatmap[np.where(cam < 0.2)] = 0\n",
        "        img = heatmap*0.5 + original_img\n",
        "        cv2.imwrite(output_path, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BVh5rtuAJzoe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**ANOTHER FINE TUNING OF VGG16**"
      ]
    },
    {
      "metadata": {
        "id": "bZygExd5J3ed",
        "colab_type": "code",
        "outputId": "ae5feb45-5305-45df-bd27-c47c687d28cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1278
        }
      },
      "cell_type": "code",
      "source": [
        "#NEW VGG16 TUNING\n",
        "\n",
        "import numpy as np\n",
        "!pip3 install keras\n",
        "#!pip3 install tensorflow==1.5.0\n",
        "!pip3 install tensorflow\n",
        "!pip install mxnet-mkl\n",
        "!pip3 install sklearn\n",
        "!pip3 install keras_tqdm\n",
        "!pip install scipy\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import *\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from keras.applications import VGG16\n",
        "#Load the VGG model\n",
        "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers except the last 4 layers\n",
        "for layer in vgg16_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        " \n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg16_model.layers:\n",
        "    print(layer, layer.trainable)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.2.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.9)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.9.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: mxnet-mkl in /usr/local/lib/python3.6/dist-packages (1.4.0.post0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (2.21.0)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (1.14.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (1.24.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2019.3.9)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.2.1)\n",
            "Requirement already satisfied: keras_tqdm in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (4.28.1)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (2.2.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.7)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.14.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.9)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.2.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "<keras.engine.input_layer.InputLayer object at 0x7f4a416cd748> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4a405f53c8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4a405ed908> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f4a40624208> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4a40617e10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4a405bed30> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f4a40567550> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4a40567400> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4a40595208> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4a40529828> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f4a40545c50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f4a405459b0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f495cf87b00> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f495cfb4278> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f495cf4db00> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f495cf4d668> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f495cf7b320> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7f495cf12d68> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7f495cebf5f8> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZEsbH3OnKx1k",
        "colab_type": "code",
        "outputId": "dab9e882-48e5-4467-b730-d50c8e36d01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        " \n",
        "# Create the model\n",
        "newVGG16_model = models.Sequential()\n",
        " \n",
        "# Add the vgg convolutional base model\n",
        "newVGG16_model.add(vgg16_model)\n",
        " \n",
        "# Add new layers\n",
        "newVGG16_model.add(layers.Flatten())\n",
        "newVGG16_model.add(layers.Dense(1024, activation='relu'))\n",
        "newVGG16_model.add(layers.Dropout(0.5))\n",
        "newVGG16_model.add(layers.Dense(3, activation='softmax'))\n",
        " \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "newVGG16_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 40,408,899\n",
            "Trainable params: 32,773,635\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RvbWegZuLykP",
        "colab_type": "code",
        "outputId": "1a2e93fd-d85c-4764-90eb-3b59eed93c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "train_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Training/Patches\"\n",
        "#train_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Training/Patches/\"\n",
        "valid_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Validation/Patches\"\n",
        "#valid_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Patches\"\n",
        "#test_path =\"/Users/Mac/Desktop/ROI-dataset-bioinf/Test/Patches\"\n",
        "test_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Test/Patches\"\n",
        "'''\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        " \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "'''\n",
        "\n",
        "'''\n",
        "train_datagen = ImageDataGenerator(rotation_range=10, shear_range=0.15, channel_shift_range=10., horizontal_flip=True)\n",
        "# Change the batchsize according to your system RAM\n",
        "train_batchsize = 100\n",
        "val_batchsize = 10\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=train_batchsize,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = ImageDataGenerator().flow_from_directory(\n",
        "        valid_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=val_batchsize,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "'''\n",
        "train_datagen = ImageDataGenerator(rescale= 1. /255)\n",
        "validation_datagen = ImageDataGenerator(rescale= 1. /255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Training/Patches',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=100,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Validation/Patches',\n",
        "    target_size=(224, 224),\n",
        "    batch_size= 100,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2263 images belonging to 3 classes.\n",
            "Found 1053 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qbhBqv8hMocM",
        "colab_type": "code",
        "outputId": "6cfc21b6-9a82-4479-d1f8-9a96217d0e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        }
      },
      "cell_type": "code",
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=2,\n",
        "                              verbose=0, mode='auto')\n",
        "\n",
        "# Compile the model\n",
        "newVGG16_model.compile(loss='categorical_crossentropy',optimizer=\n",
        "              SGD(lr=0.0001, momentum=0.9, decay=0.0, nesterov=True),\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "history = newVGG16_model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
        "      verbose=1)#, callbacks=[es])\n",
        " \n",
        "# Save the model\n",
        "newVGG16_model.save('/content/gdrive/My Drive/Bioinformatica/newVGG16.h6')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "23/22 [==============================] - 23s 1s/step - loss: 1.1825 - acc: 0.3779 - val_loss: 0.9900 - val_acc: 0.5708\n",
            "Epoch 2/100\n",
            "23/22 [==============================] - 20s 882ms/step - loss: 0.8914 - acc: 0.5824 - val_loss: 0.8358 - val_acc: 0.6277\n",
            "Epoch 3/100\n",
            "23/22 [==============================] - 20s 860ms/step - loss: 0.6830 - acc: 0.7204 - val_loss: 0.7511 - val_acc: 0.6239\n",
            "Epoch 4/100\n",
            "23/22 [==============================] - 19s 837ms/step - loss: 0.5392 - acc: 0.7844 - val_loss: 0.6519 - val_acc: 0.6543\n",
            "Epoch 5/100\n",
            "23/22 [==============================] - 19s 838ms/step - loss: 0.4392 - acc: 0.8245 - val_loss: 0.6140 - val_acc: 0.6657\n",
            "Epoch 6/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.4046 - acc: 0.8302 - val_loss: 0.6002 - val_acc: 0.6828\n",
            "Epoch 7/100\n",
            "23/22 [==============================] - 20s 857ms/step - loss: 0.3586 - acc: 0.8568 - val_loss: 0.6115 - val_acc: 0.6828\n",
            "Epoch 8/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.3166 - acc: 0.8711 - val_loss: 0.6015 - val_acc: 0.6914\n",
            "Epoch 9/100\n",
            "23/22 [==============================] - 19s 846ms/step - loss: 0.2988 - acc: 0.8786 - val_loss: 0.5362 - val_acc: 0.7217\n",
            "Epoch 10/100\n",
            "23/22 [==============================] - 19s 848ms/step - loss: 0.2788 - acc: 0.8933 - val_loss: 0.6343 - val_acc: 0.7009\n",
            "Epoch 11/100\n",
            "23/22 [==============================] - 19s 847ms/step - loss: 0.2597 - acc: 0.8885 - val_loss: 0.6690 - val_acc: 0.7018\n",
            "Epoch 12/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.2414 - acc: 0.9011 - val_loss: 0.6114 - val_acc: 0.7217\n",
            "Epoch 13/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.2242 - acc: 0.9084 - val_loss: 0.6267 - val_acc: 0.7217\n",
            "Epoch 14/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.2164 - acc: 0.9177 - val_loss: 0.5587 - val_acc: 0.7436\n",
            "Epoch 15/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.2102 - acc: 0.9130 - val_loss: 0.7201 - val_acc: 0.7113\n",
            "Epoch 16/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.1997 - acc: 0.9224 - val_loss: 0.6162 - val_acc: 0.7379\n",
            "Epoch 17/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.1807 - acc: 0.9307 - val_loss: 0.6868 - val_acc: 0.7312\n",
            "Epoch 18/100\n",
            "23/22 [==============================] - 20s 848ms/step - loss: 0.1713 - acc: 0.9418 - val_loss: 0.6352 - val_acc: 0.7436\n",
            "Epoch 19/100\n",
            "23/22 [==============================] - 19s 847ms/step - loss: 0.1692 - acc: 0.9367 - val_loss: 0.7402 - val_acc: 0.7246\n",
            "Epoch 20/100\n",
            "23/22 [==============================] - 19s 848ms/step - loss: 0.1628 - acc: 0.9359 - val_loss: 0.5432 - val_acc: 0.7787\n",
            "Epoch 21/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.1518 - acc: 0.9435 - val_loss: 0.6513 - val_acc: 0.7493\n",
            "Epoch 22/100\n",
            "23/22 [==============================] - 20s 852ms/step - loss: 0.1437 - acc: 0.9474 - val_loss: 0.5846 - val_acc: 0.7730\n",
            "Epoch 23/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.1398 - acc: 0.9512 - val_loss: 0.6950 - val_acc: 0.7445\n",
            "Epoch 24/100\n",
            "23/22 [==============================] - 20s 853ms/step - loss: 0.1346 - acc: 0.9502 - val_loss: 0.6228 - val_acc: 0.7654\n",
            "Epoch 25/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.1265 - acc: 0.9513 - val_loss: 0.6011 - val_acc: 0.7749\n",
            "Epoch 26/100\n",
            "23/22 [==============================] - 20s 852ms/step - loss: 0.1211 - acc: 0.9567 - val_loss: 0.5966 - val_acc: 0.7835\n",
            "Epoch 27/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.1101 - acc: 0.9649 - val_loss: 0.5962 - val_acc: 0.7778\n",
            "Epoch 28/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.1145 - acc: 0.9605 - val_loss: 0.5910 - val_acc: 0.7854\n",
            "Epoch 29/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.1083 - acc: 0.9609 - val_loss: 0.5816 - val_acc: 0.7920\n",
            "Epoch 30/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.1093 - acc: 0.9592 - val_loss: 0.6225 - val_acc: 0.7806\n",
            "Epoch 31/100\n",
            "23/22 [==============================] - 20s 852ms/step - loss: 0.1068 - acc: 0.9566 - val_loss: 0.5594 - val_acc: 0.7958\n",
            "Epoch 32/100\n",
            "23/22 [==============================] - 20s 848ms/step - loss: 0.0994 - acc: 0.9638 - val_loss: 0.6024 - val_acc: 0.7854\n",
            "Epoch 33/100\n",
            "23/22 [==============================] - 19s 847ms/step - loss: 0.0965 - acc: 0.9658 - val_loss: 0.5410 - val_acc: 0.8072\n",
            "Epoch 34/100\n",
            "23/22 [==============================] - 19s 847ms/step - loss: 0.0925 - acc: 0.9671 - val_loss: 0.6161 - val_acc: 0.7787\n",
            "Epoch 35/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0869 - acc: 0.9680 - val_loss: 0.4804 - val_acc: 0.8291\n",
            "Epoch 36/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0858 - acc: 0.9721 - val_loss: 0.4540 - val_acc: 0.8367\n",
            "Epoch 37/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0792 - acc: 0.9737 - val_loss: 0.5002 - val_acc: 0.8215\n",
            "Epoch 38/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.0813 - acc: 0.9748 - val_loss: 0.5054 - val_acc: 0.8215\n",
            "Epoch 39/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0746 - acc: 0.9761 - val_loss: 0.5617 - val_acc: 0.8063\n",
            "Epoch 40/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0830 - acc: 0.9715 - val_loss: 0.5223 - val_acc: 0.8148\n",
            "Epoch 41/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0720 - acc: 0.9804 - val_loss: 0.4543 - val_acc: 0.8424\n",
            "Epoch 42/100\n",
            "23/22 [==============================] - 19s 847ms/step - loss: 0.0705 - acc: 0.9780 - val_loss: 0.4937 - val_acc: 0.8243\n",
            "Epoch 43/100\n",
            "23/22 [==============================] - 19s 848ms/step - loss: 0.0686 - acc: 0.9797 - val_loss: 0.4320 - val_acc: 0.8500\n",
            "Epoch 44/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0640 - acc: 0.9797 - val_loss: 0.4926 - val_acc: 0.8243\n",
            "Epoch 45/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0660 - acc: 0.9771 - val_loss: 0.4971 - val_acc: 0.8234\n",
            "Epoch 46/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0617 - acc: 0.9778 - val_loss: 0.5242 - val_acc: 0.8167\n",
            "Epoch 47/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0664 - acc: 0.9788 - val_loss: 0.4231 - val_acc: 0.8490\n",
            "Epoch 48/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.0622 - acc: 0.9795 - val_loss: 0.4826 - val_acc: 0.8329\n",
            "Epoch 49/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0629 - acc: 0.9778 - val_loss: 0.4746 - val_acc: 0.8348\n",
            "Epoch 50/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0578 - acc: 0.9802 - val_loss: 0.3691 - val_acc: 0.8557\n",
            "Epoch 51/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0570 - acc: 0.9819 - val_loss: 0.5984 - val_acc: 0.8025\n",
            "Epoch 52/100\n",
            "23/22 [==============================] - 19s 847ms/step - loss: 0.0509 - acc: 0.9841 - val_loss: 0.4638 - val_acc: 0.8386\n",
            "Epoch 53/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0528 - acc: 0.9850 - val_loss: 0.5135 - val_acc: 0.8215\n",
            "Epoch 54/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.0494 - acc: 0.9878 - val_loss: 0.4929 - val_acc: 0.8272\n",
            "Epoch 55/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0502 - acc: 0.9874 - val_loss: 0.4423 - val_acc: 0.8414\n",
            "Epoch 56/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0544 - acc: 0.9813 - val_loss: 0.4892 - val_acc: 0.8329\n",
            "Epoch 57/100\n",
            "23/22 [==============================] - 20s 848ms/step - loss: 0.0453 - acc: 0.9858 - val_loss: 0.4351 - val_acc: 0.8443\n",
            "Epoch 58/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0440 - acc: 0.9884 - val_loss: 0.5733 - val_acc: 0.8129\n",
            "Epoch 59/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0461 - acc: 0.9874 - val_loss: 0.4125 - val_acc: 0.8490\n",
            "Epoch 60/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0407 - acc: 0.9874 - val_loss: 0.4660 - val_acc: 0.8386\n",
            "Epoch 61/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.0410 - acc: 0.9900 - val_loss: 0.4904 - val_acc: 0.8319\n",
            "Epoch 62/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0406 - acc: 0.9878 - val_loss: 0.5186 - val_acc: 0.8291\n",
            "Epoch 63/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0407 - acc: 0.9904 - val_loss: 0.4317 - val_acc: 0.8414\n",
            "Epoch 64/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.0403 - acc: 0.9906 - val_loss: 0.5006 - val_acc: 0.8367\n",
            "Epoch 65/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0385 - acc: 0.9904 - val_loss: 0.4760 - val_acc: 0.8376\n",
            "Epoch 66/100\n",
            "23/22 [==============================] - 20s 848ms/step - loss: 0.0398 - acc: 0.9900 - val_loss: 0.4733 - val_acc: 0.8357\n",
            "Epoch 67/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0377 - acc: 0.9904 - val_loss: 0.5314 - val_acc: 0.8234\n",
            "Epoch 68/100\n",
            "23/22 [==============================] - 20s 848ms/step - loss: 0.0384 - acc: 0.9884 - val_loss: 0.3946 - val_acc: 0.8547\n",
            "Epoch 69/100\n",
            "23/22 [==============================] - 20s 848ms/step - loss: 0.0366 - acc: 0.9913 - val_loss: 0.3731 - val_acc: 0.8585\n",
            "Epoch 70/100\n",
            "23/22 [==============================] - 20s 854ms/step - loss: 0.0346 - acc: 0.9909 - val_loss: 0.5018 - val_acc: 0.8386\n",
            "Epoch 71/100\n",
            "23/22 [==============================] - 19s 847ms/step - loss: 0.0358 - acc: 0.9883 - val_loss: 0.4034 - val_acc: 0.8490\n",
            "Epoch 72/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0337 - acc: 0.9906 - val_loss: 0.4954 - val_acc: 0.8386\n",
            "Epoch 73/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0322 - acc: 0.9904 - val_loss: 0.3844 - val_acc: 0.8566\n",
            "Epoch 74/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.0321 - acc: 0.9884 - val_loss: 0.4189 - val_acc: 0.8490\n",
            "Epoch 75/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.0298 - acc: 0.9932 - val_loss: 0.5130 - val_acc: 0.8348\n",
            "Epoch 76/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0321 - acc: 0.9939 - val_loss: 0.4240 - val_acc: 0.8471\n",
            "Epoch 77/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0283 - acc: 0.9930 - val_loss: 0.4087 - val_acc: 0.8557\n",
            "Epoch 78/100\n",
            "23/22 [==============================] - 20s 848ms/step - loss: 0.0286 - acc: 0.9939 - val_loss: 0.4757 - val_acc: 0.8414\n",
            "Epoch 79/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0274 - acc: 0.9935 - val_loss: 0.3798 - val_acc: 0.8594\n",
            "Epoch 80/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0273 - acc: 0.9956 - val_loss: 0.4083 - val_acc: 0.8538\n",
            "Epoch 81/100\n",
            "23/22 [==============================] - 20s 848ms/step - loss: 0.0303 - acc: 0.9919 - val_loss: 0.4736 - val_acc: 0.8405\n",
            "Epoch 82/100\n",
            "23/22 [==============================] - 20s 848ms/step - loss: 0.0249 - acc: 0.9937 - val_loss: 0.4361 - val_acc: 0.8519\n",
            "Epoch 83/100\n",
            "23/22 [==============================] - 19s 847ms/step - loss: 0.0269 - acc: 0.9941 - val_loss: 0.4096 - val_acc: 0.8557\n",
            "Epoch 84/100\n",
            "23/22 [==============================] - 20s 848ms/step - loss: 0.0256 - acc: 0.9948 - val_loss: 0.4804 - val_acc: 0.8395\n",
            "Epoch 85/100\n",
            "23/22 [==============================] - 20s 848ms/step - loss: 0.0239 - acc: 0.9965 - val_loss: 0.4169 - val_acc: 0.8528\n",
            "Epoch 86/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0250 - acc: 0.9937 - val_loss: 0.4774 - val_acc: 0.8395\n",
            "Epoch 87/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.0260 - acc: 0.9937 - val_loss: 0.3937 - val_acc: 0.8585\n",
            "Epoch 88/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0223 - acc: 0.9965 - val_loss: 0.4292 - val_acc: 0.8547\n",
            "Epoch 89/100\n",
            "23/22 [==============================] - 20s 851ms/step - loss: 0.0236 - acc: 0.9952 - val_loss: 0.3528 - val_acc: 0.8623\n",
            "Epoch 90/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0210 - acc: 0.9961 - val_loss: 0.4629 - val_acc: 0.8462\n",
            "Epoch 91/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0222 - acc: 0.9950 - val_loss: 0.5644 - val_acc: 0.8281\n",
            "Epoch 92/100\n",
            "23/22 [==============================] - 19s 848ms/step - loss: 0.0218 - acc: 0.9970 - val_loss: 0.3562 - val_acc: 0.8680\n",
            "Epoch 93/100\n",
            "23/22 [==============================] - 19s 848ms/step - loss: 0.0208 - acc: 0.9956 - val_loss: 0.4232 - val_acc: 0.8557\n",
            "Epoch 94/100\n",
            "23/22 [==============================] - 19s 847ms/step - loss: 0.0199 - acc: 0.9970 - val_loss: 0.4497 - val_acc: 0.8509\n",
            "Epoch 95/100\n",
            "23/22 [==============================] - 19s 847ms/step - loss: 0.0205 - acc: 0.9974 - val_loss: 0.4603 - val_acc: 0.8500\n",
            "Epoch 96/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0201 - acc: 0.9952 - val_loss: 0.3850 - val_acc: 0.8613\n",
            "Epoch 97/100\n",
            "23/22 [==============================] - 20s 850ms/step - loss: 0.0226 - acc: 0.9948 - val_loss: 0.4974 - val_acc: 0.8424\n",
            "Epoch 98/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0200 - acc: 0.9952 - val_loss: 0.4530 - val_acc: 0.8547\n",
            "Epoch 99/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0195 - acc: 0.9970 - val_loss: 0.4495 - val_acc: 0.8547\n",
            "Epoch 100/100\n",
            "23/22 [==============================] - 20s 849ms/step - loss: 0.0196 - acc: 0.9948 - val_loss: 0.4793 - val_acc: 0.8462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xsHhyqywXtMI",
        "colab_type": "code",
        "outputId": "8ae5f970-ec49-43dd-91c2-c654edaf861f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "newVGG16 = load_model('/content/gdrive/My Drive/Bioinformatica/newVGG16.h5')\n",
        "\n",
        "generator = ImageDataGenerator().flow_from_directory(\n",
        "        '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Test/Patches',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=100)\n",
        "\n",
        "probabilities = newVGG16_model.predict_generator(generator, 1)\n",
        "#probabilities = np.argmax(probabilities, axis=-1) #multiple categories"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 437 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CPSQ2ztv0BSL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "#This function prints and plots the confusion matrix.\n",
        "#Normalization can ben applied by setting 'normalize-True'\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks=np.arange(len(classes))\n",
        "    plt.xticks(tick_marks,classes,rotation=45)\n",
        "    plt.yticks(tick_marks,classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2\n",
        "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "           plt.text(j, i, \"{:0.2f}\".format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "        else:\n",
        "           plt.text(j, i, format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9QHDhLbHMy1p",
        "colab_type": "code",
        "outputId": "ad6b048f-fe75-4e9a-f878-24d7079d28f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -U scikit-learn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#MULTI-LABEL CONFUSION MATRIX\n",
        "test_dir, test_labels = next(generator)\n",
        "test_img = [ np.argmax(t) for t in test_labels ]\n",
        "num_pred = [ np.argmax(t) for t in probabilities ]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(test_img, num_pred)\n",
        "\n",
        "cm_plot_labels = ['Benign','Healthy','Cancer']\n",
        "plot_confusion_matrix(conf_mat,cm_plot_labels,normalize=False,title ='Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.20.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.2.1)\n",
            "Confusion matrix, without normalization\n",
            "[[12  6 18]\n",
            " [ 7  4 21]\n",
            " [ 6  4 22]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEmCAYAAADmw8JdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h/VGH7prytTcAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2ctEn5o83EFe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**FINE TUNING RESNET50**"
      ]
    },
    {
      "metadata": {
        "id": "dHRqp23fGCzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1312
        },
        "outputId": "2c3a4ada-824e-484f-a506-b6f09e5ad271"
      },
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install h5py\n",
        "!pip3 install tensorflow\n",
        "!pip install mxnet-mkl\n",
        "!pip3 install sklearn\n",
        "!pip3 install keras_tqdm\n",
        "!pip install scipy\n",
        "!pip install -U --force-reinstall --no-dependencies git+https://github.com/datumbox/keras@bugfix/trainable_bn\n",
        "#http://blog.datumbox.com/the-batch-normalization-layer-of-keras-is-broken/\n",
        "\n",
        "!pip install -U coremltools\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model,load_model\n",
        "from keras.layers import *\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adadelta, SGD\n",
        "from keras import regularizers\n",
        "import keras\n",
        "import math, os, sys\n",
        "import matplotlib.pyplot as plt\n",
        "import coremltools\n",
        "import numpy as np\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "from sklearn.metrics import *\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.2.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: mxnet-mkl in /usr/local/lib/python3.6/dist-packages (1.4.0.post0)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (1.14.6)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (1.24.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (3.0.4)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.2.1)\n",
            "Requirement already satisfied: keras_tqdm in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (2.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (4.28.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.9)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.14.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (2.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n",
            "Collecting git+https://github.com/datumbox/keras@bugfix/trainable_bn\n",
            "  Cloning https://github.com/datumbox/keras (to revision bugfix/trainable_bn) to /tmp/pip-req-build-zeq1vr75\n",
            "Branch 'bugfix/trainable_bn' set up to track remote branch 'bugfix/trainable_bn' from 'origin'.\n",
            "Switched to a new branch 'bugfix/trainable_bn'\n",
            "Building wheels for collected packages: Keras\n",
            "  Building wheel for Keras (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-caws_8_v/wheels/36/5d/50/99c268bf64c1394c4f5b743164e4e515ab30290a523595ac47\n",
            "Successfully built Keras\n",
            "Installing collected packages: Keras\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "Successfully installed Keras-2.2.4\n",
            "Requirement already up-to-date: coremltools in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from coremltools) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from coremltools) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from coremltools) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->coremltools) (40.9.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:root:TensorFlow version 1.13.1 detected. Last version known to be fully compatible is 1.12.0 .\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XRRwropzP3BP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "660401d7-0d16-41e6-cb87-87adde6f74bf"
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "  \n",
        "    input_tensor = Input(shape=(64, 64, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
        "\n",
        "    # create the base pre-trained model\n",
        "    base_model = ResNet50(input_tensor=input_tensor,weights='imagenet',include_top=False)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable=False\n",
        "        \n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "    #kernel_regularizer=regularizers.l2(0.01),\n",
        "    #activity_regularizer=regularizers.l1(0.01)\n",
        "\n",
        "    updatedModel = Model(base_model.input, x)\n",
        "\n",
        "    return  updatedModel\n",
        "\n",
        "\n",
        "\n",
        "def compile_model(compiledModel):\n",
        "    #I tried SGD compiler instead of Adadelta\n",
        "    compiledModel.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "def modelFitGenerator(fitModel):\n",
        "\n",
        "    num_train_samples = sum([len(files) for r, d, files in os.walk(train_data_dir)])\n",
        "    num_valid_samples = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
        "\n",
        "    num_train_steps = math.floor(num_train_samples/batch_size)\n",
        "    num_valid_steps = math.floor(num_valid_samples/batch_size)\n",
        "    \n",
        "    train_datagen = ImageDataGenerator(  \n",
        "      rotation_range=90,      \n",
        "      horizontal_flip=True,    \n",
        "      vertical_flip=True,\n",
        "      zoom_range=0.4)\n",
        "\n",
        "    valid_datagen = ImageDataGenerator()\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "      train_data_dir,\n",
        "      target_size=image_size ,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical', classes=['Benign', 'Healthy', 'Cancer'], shuffle=True\n",
        "    )\n",
        "\n",
        "    validation_generator = valid_datagen.flow_from_directory(\n",
        "      validation_data_dir,\n",
        "      target_size=image_size ,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical',classes=['Benign', 'Healthy', 'Cancer'], shuffle=True\n",
        "    )\n",
        "\n",
        "    print(\"start history model\")\n",
        "    history = fitModel.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=num_train_steps,\n",
        "      epochs=nb_epoch,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=num_valid_steps, verbose=1)\n",
        "    \n",
        "    printGraph(history)\n",
        "\n",
        "def printGraph(history):\n",
        "    \n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "def saveCoreMLModel(kerasModel):\n",
        "    coreml_model = coremltools.converters.keras.convert(kerasModel,\n",
        "                                                        input_names=['input'],\n",
        "                                                        output_names=['probs'],\n",
        "                                                        image_input_names='input',\n",
        "                                                        predicted_feature_name='predictedTumor',\n",
        "                                                        class_labels = ['Benign', 'Healthy', 'Cancer'])\n",
        "    coreml_model.save('resnet50custom.mlmodel') \n",
        "    print('CoreML model saved')\n",
        "        \n",
        "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "    #This function prints and plots the confusion matrix.\n",
        "    #Normalization can ben applied by setting 'normalize-True'\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks=np.arange(len(classes))\n",
        "    plt.xticks(tick_marks,classes,rotation=45)\n",
        "    plt.yticks(tick_marks,classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "        print(cm)\n",
        "\n",
        "        thresh = cm.max() / 2\n",
        "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "           plt.text(j, i, \"{:0.2f}\".format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "        else:\n",
        "           plt.text(j, i, format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')\n",
        "    \n",
        "def print_predictions(model):\n",
        "        \n",
        "    test_generator = ImageDataGenerator().flow_from_directory(\n",
        "        '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Test/Patches',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=437, class_mode='categorical', classes=['Benign', 'Healthy', 'Cancer'])\n",
        "\n",
        "    probabilities = model.predict_generator(test_generator, 1)\n",
        "\n",
        "    !pip3 install -U scikit-learn\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    #MULTI-LABEL CONFUSION MATRIX\n",
        "    test_dir, test_labels = next(test_generator)\n",
        "    test_img = [ np.argmax(t) for t in test_labels ]\n",
        "    num_pred = [ np.argmax(t) for t in probabilities ]\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    conf_mat = confusion_matrix(test_img, num_pred)\n",
        "\n",
        "    cm_plot_labels = ['Benign','Healthy','Cancer']\n",
        "    plot_confusion_matrix(conf_mat,cm_plot_labels,normalize=False,title ='Confusion Matrix')\n",
        "\n",
        "'''\n",
        "def main():\n",
        "    ResNetModel = get_model()\n",
        "    compile_model(ResNetModel)\n",
        "    modelFitGenerator(ResNetModel)\n",
        "    #saveCoreMLModel(ResNetModel)\n",
        "    print_predictions(ResNetModel)\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # constants\n",
        "    image_size = (224, 224)\n",
        "    train_data_dir = '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Training/Patches' \n",
        "    validation_data_dir = '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Validation/Patches'\n",
        "    nb_epoch = 30\n",
        "    batch_size = 32\n",
        "    num_classes = 3\n",
        "    main()\n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef main():\\n    ResNetModel = get_model()\\n    compile_model(ResNetModel)\\n    modelFitGenerator(ResNetModel)\\n    #saveCoreMLModel(ResNetModel)\\n    print_predictions(ResNetModel)\\n    \\n\\nif __name__ == '__main__':\\n    # constants\\n    image_size = (224, 224)\\n    train_data_dir = '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Training/Patches' \\n    validation_data_dir = '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Validation/Patches'\\n    nb_epoch = 30\\n    batch_size = 32\\n    num_classes = 3\\n    main()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "ueFJMeSRB963",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5082
        },
        "outputId": "8f0080ba-abde-4b8c-a2f1-ca7a00d75b45"
      },
      "cell_type": "code",
      "source": [
        "    image_size = (64, 64)\n",
        "    train_data_dir = '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Training/Patches' \n",
        "    validation_data_dir = '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Validation/Patches'\n",
        "    nb_epoch = 30\n",
        "    batch_size = 100\n",
        "    num_classes = 3\n",
        "    ResNetModel = get_model()\n",
        "    compile_model(ResNetModel)\n",
        "    modelFitGenerator(ResNetModel)\n",
        "    saveCoreMLModel(ResNetModel)\n",
        "    print_predictions(ResNetModel)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 2608 images belonging to 3 classes.\n",
            "Found 697 images belonging to 3 classes.\n",
            "start history model\n",
            "Epoch 1/30\n",
            "26/26 [==============================] - 10s 388ms/step - loss: 0.5693 - acc: 0.7804 - val_loss: 0.4437 - val_acc: 0.8083\n",
            "Epoch 2/30\n",
            "26/26 [==============================] - 6s 225ms/step - loss: 0.3110 - acc: 0.8744 - val_loss: 0.3615 - val_acc: 0.8375\n",
            "Epoch 3/30\n",
            "26/26 [==============================] - 7s 266ms/step - loss: 0.2570 - acc: 0.9072 - val_loss: 0.2818 - val_acc: 0.8844\n",
            "Epoch 4/30\n",
            "26/26 [==============================] - 7s 264ms/step - loss: 0.2715 - acc: 0.9087 - val_loss: 0.3868 - val_acc: 0.8291\n",
            "Epoch 5/30\n",
            "26/26 [==============================] - 7s 267ms/step - loss: 0.2299 - acc: 0.9168 - val_loss: 0.3096 - val_acc: 0.8878\n",
            "Epoch 6/30\n",
            "26/26 [==============================] - 9s 330ms/step - loss: 0.2112 - acc: 0.9149 - val_loss: 0.2779 - val_acc: 0.8911\n",
            "Epoch 7/30\n",
            "26/26 [==============================] - 7s 274ms/step - loss: 0.1950 - acc: 0.9257 - val_loss: 0.2769 - val_acc: 0.8928\n",
            "Epoch 8/30\n",
            "26/26 [==============================] - 7s 266ms/step - loss: 0.1838 - acc: 0.9287 - val_loss: 0.3527 - val_acc: 0.8700\n",
            "Epoch 9/30\n",
            "26/26 [==============================] - 8s 298ms/step - loss: 0.2027 - acc: 0.9272 - val_loss: 0.2246 - val_acc: 0.9112\n",
            "Epoch 10/30\n",
            "26/26 [==============================] - 7s 284ms/step - loss: 0.1884 - acc: 0.9268 - val_loss: 0.3088 - val_acc: 0.8760\n",
            "Epoch 11/30\n",
            "26/26 [==============================] - 7s 265ms/step - loss: 0.1952 - acc: 0.9318 - val_loss: 0.3901 - val_acc: 0.8476\n",
            "Epoch 12/30\n",
            "26/26 [==============================] - 8s 289ms/step - loss: 0.1940 - acc: 0.9310 - val_loss: 0.3752 - val_acc: 0.8643\n",
            "Epoch 13/30\n",
            "26/26 [==============================] - 7s 273ms/step - loss: 0.1789 - acc: 0.9372 - val_loss: 0.4488 - val_acc: 0.8275\n",
            "Epoch 14/30\n",
            "26/26 [==============================] - 7s 264ms/step - loss: 0.1964 - acc: 0.9276 - val_loss: 0.3604 - val_acc: 0.8660\n",
            "Epoch 15/30\n",
            "26/26 [==============================] - 7s 264ms/step - loss: 0.1640 - acc: 0.9403 - val_loss: 0.3527 - val_acc: 0.8700\n",
            "Epoch 16/30\n",
            "26/26 [==============================] - 7s 264ms/step - loss: 0.1742 - acc: 0.9365 - val_loss: 0.3259 - val_acc: 0.8794\n",
            "Epoch 17/30\n",
            "26/26 [==============================] - 7s 264ms/step - loss: 0.1728 - acc: 0.9380 - val_loss: 0.2576 - val_acc: 0.9045\n",
            "Epoch 18/30\n",
            "26/26 [==============================] - 7s 265ms/step - loss: 0.1515 - acc: 0.9445 - val_loss: 0.4401 - val_acc: 0.8442\n",
            "Epoch 19/30\n",
            "26/26 [==============================] - 7s 265ms/step - loss: 0.1617 - acc: 0.9395 - val_loss: 0.2925 - val_acc: 0.8894\n",
            "Epoch 20/30\n",
            "26/26 [==============================] - 7s 283ms/step - loss: 0.1475 - acc: 0.9449 - val_loss: 0.4385 - val_acc: 0.8610\n",
            "Epoch 21/30\n",
            "26/26 [==============================] - 8s 298ms/step - loss: 0.1656 - acc: 0.9349 - val_loss: 0.3906 - val_acc: 0.8593\n",
            "Epoch 22/30\n",
            "26/26 [==============================] - 7s 264ms/step - loss: 0.1734 - acc: 0.9399 - val_loss: 0.5601 - val_acc: 0.8067\n",
            "Epoch 23/30\n",
            "26/26 [==============================] - 7s 265ms/step - loss: 0.1503 - acc: 0.9457 - val_loss: 0.3668 - val_acc: 0.8777\n",
            "Epoch 24/30\n",
            "26/26 [==============================] - 7s 266ms/step - loss: 0.1566 - acc: 0.9484 - val_loss: 0.3257 - val_acc: 0.8811\n",
            "Epoch 25/30\n",
            "26/26 [==============================] - 7s 264ms/step - loss: 0.1715 - acc: 0.9422 - val_loss: 0.2721 - val_acc: 0.8928\n",
            "Epoch 26/30\n",
            "26/26 [==============================] - 7s 265ms/step - loss: 0.1499 - acc: 0.9453 - val_loss: 0.3551 - val_acc: 0.8693\n",
            "Epoch 27/30\n",
            "26/26 [==============================] - 7s 267ms/step - loss: 0.1495 - acc: 0.9399 - val_loss: 0.3169 - val_acc: 0.8878\n",
            "Epoch 28/30\n",
            "26/26 [==============================] - 7s 274ms/step - loss: 0.1607 - acc: 0.9400 - val_loss: 0.3478 - val_acc: 0.8727\n",
            "Epoch 29/30\n",
            "26/26 [==============================] - 7s 266ms/step - loss: 0.1435 - acc: 0.9442 - val_loss: 0.3227 - val_acc: 0.8850\n",
            "Epoch 30/30\n",
            "26/26 [==============================] - 7s 264ms/step - loss: 0.1517 - acc: 0.9469 - val_loss: 0.4177 - val_acc: 0.8543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmJlZWxxIzMysLQ4kZmbWFgcSMzNry/8DM+BKuIlcZdIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFCRJA4uCJGlgUZAkDSwKkqTBH39LyMJDQY1nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0 : input_2, <keras.engine.input_layer.InputLayer object at 0x7f83817240f0>\n",
            "1 : conv1_pad, <keras.layers.convolutional.ZeroPadding2D object at 0x7f8381724128>\n",
            "2 : conv1, <keras.layers.convolutional.Conv2D object at 0x7f8381724080>\n",
            "3 : bn_conv1, <keras.layers.normalization.BatchNormalization object at 0x7f8381724470>\n",
            "4 : activation_50, <keras.layers.core.Activation object at 0x7f83817247b8>\n",
            "5 : pool1_pad, <keras.layers.convolutional.ZeroPadding2D object at 0x7f8381732710>\n",
            "6 : max_pooling2d_2, <keras.layers.pooling.MaxPooling2D object at 0x7f8381732828>\n",
            "7 : res2a_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f83816c4828>\n",
            "8 : bn2a_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f838160b358>\n",
            "9 : activation_51, <keras.layers.core.Activation object at 0x7f838160bef0>\n",
            "10 : res2a_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f83815d1e48>\n",
            "11 : bn2a_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f838158de80>\n",
            "12 : activation_52, <keras.layers.core.Activation object at 0x7f83815a9e10>\n",
            "13 : res2a_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f83814ed5c0>\n",
            "14 : res2a_branch1, <keras.layers.convolutional.Conv2D object at 0x7f8381446e10>\n",
            "15 : bn2a_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f83814aafd0>\n",
            "16 : bn2a_branch1, <keras.layers.normalization.BatchNormalization object at 0x7f83813ac978>\n",
            "17 : add_17, <keras.layers.merge.Add object at 0x7f8381349dd8>\n",
            "18 : activation_53, <keras.layers.core.Activation object at 0x7f838124f898>\n",
            "19 : res2b_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f8381272cc0>\n",
            "20 : bn2b_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f8381210470>\n",
            "21 : activation_54, <keras.layers.core.Activation object at 0x7f83811872e8>\n",
            "22 : res2b_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f83811455f8>\n",
            "23 : bn2b_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f83810870b8>\n",
            "24 : activation_55, <keras.layers.core.Activation object at 0x7f8381132f28>\n",
            "25 : res2b_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f83810182e8>\n",
            "26 : bn2b_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f8362c56a20>\n",
            "27 : add_18, <keras.layers.merge.Add object at 0x7f8362c77208>\n",
            "28 : activation_56, <keras.layers.core.Activation object at 0x7f8362b907b8>\n",
            "29 : res2c_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f8362b7b550>\n",
            "30 : bn2c_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f8362b193c8>\n",
            "31 : activation_57, <keras.layers.core.Activation object at 0x7f8362ae8cc0>\n",
            "32 : res2c_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f8362a62860>\n",
            "33 : bn2c_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f8362a1df98>\n",
            "34 : activation_58, <keras.layers.core.Activation object at 0x7f8362a3d550>\n",
            "35 : res2c_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f8362902a20>\n",
            "36 : bn2c_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f83628c3a90>\n",
            "37 : add_19, <keras.layers.merge.Add object at 0x7f8362874898>\n",
            "38 : activation_59, <keras.layers.core.Activation object at 0x7f83627c54e0>\n",
            "39 : res3a_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f83627e4f60>\n",
            "40 : bn3a_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f8362f37e48>\n",
            "41 : activation_60, <keras.layers.core.Activation object at 0x7f8362ed8d68>\n",
            "42 : res3a_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f83621c0278>\n",
            "43 : bn3a_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f83621c97f0>\n",
            "44 : activation_61, <keras.layers.core.Activation object at 0x7f836220cf98>\n",
            "45 : res3a_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f83621c8d68>\n",
            "46 : res3a_branch1, <keras.layers.convolutional.Conv2D object at 0x7f836258a908>\n",
            "47 : bn3a_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f836277ceb8>\n",
            "48 : bn3a_branch1, <keras.layers.normalization.BatchNormalization object at 0x7f83624f35f8>\n",
            "49 : add_20, <keras.layers.merge.Add object at 0x7f8362493860>\n",
            "50 : activation_62, <keras.layers.core.Activation object at 0x7f8362081c18>\n",
            "51 : res3b_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f8362078b00>\n",
            "52 : bn3b_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f8347fd1c50>\n",
            "53 : activation_63, <keras.layers.core.Activation object at 0x7f8347f452b0>\n",
            "54 : res3b_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f8347f34780>\n",
            "55 : bn3b_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f8347ecee48>\n",
            "56 : activation_64, <keras.layers.core.Activation object at 0x7f8347ef1f60>\n",
            "57 : res3b_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f8347e255f8>\n",
            "58 : bn3b_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f8347d922e8>\n",
            "59 : add_21, <keras.layers.merge.Add object at 0x7f8347db62b0>\n",
            "60 : activation_65, <keras.layers.core.Activation object at 0x7f8347c99fd0>\n",
            "61 : res3c_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f8347cb6588>\n",
            "62 : bn3c_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f8347c55400>\n",
            "63 : activation_66, <keras.layers.core.Activation object at 0x7f8347c22d30>\n",
            "64 : res3c_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f8347bb5550>\n",
            "65 : bn3c_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f8347b55a58>\n",
            "66 : activation_67, <keras.layers.core.Activation object at 0x7f8347a87860>\n",
            "67 : res3c_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f8347a574e0>\n",
            "68 : bn3c_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f8347a72c50>\n",
            "69 : add_22, <keras.layers.merge.Add object at 0x7f8347a15fd0>\n",
            "70 : activation_68, <keras.layers.core.Activation object at 0x7f8347947198>\n",
            "71 : res3d_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f8347917f28>\n",
            "72 : bn3d_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f83479396a0>\n",
            "73 : activation_69, <keras.layers.core.Activation object at 0x7f83478a64e0>\n",
            "74 : res3d_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f834781af28>\n",
            "75 : bn3d_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f83477d74e0>\n",
            "76 : activation_70, <keras.layers.core.Activation object at 0x7f83477f8278>\n",
            "77 : res3d_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f83476dd2b0>\n",
            "78 : bn3d_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f83476f7eb8>\n",
            "79 : add_23, <keras.layers.merge.Add object at 0x7f8347696908>\n",
            "80 : activation_71, <keras.layers.core.Activation object at 0x7f834762e5c0>\n",
            "81 : res4a_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f834759ca90>\n",
            "82 : bn4a_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f834753d278>\n",
            "83 : activation_72, <keras.layers.core.Activation object at 0x7f8347532240>\n",
            "84 : res4a_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f834749b6d8>\n",
            "85 : bn4a_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f83474b7f28>\n",
            "86 : activation_73, <keras.layers.core.Activation object at 0x7f834745a5c0>\n",
            "87 : res4a_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f8347392550>\n",
            "88 : res4a_branch1, <keras.layers.convolutional.Conv2D object at 0x7f8347302898>\n",
            "89 : bn4a_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f8347302550>\n",
            "90 : bn4a_branch1, <keras.layers.normalization.BatchNormalization object at 0x7f83471c0390>\n",
            "91 : add_24, <keras.layers.merge.Add object at 0x7f834721f9e8>\n",
            "92 : activation_74, <keras.layers.core.Activation object at 0x7f834714fba8>\n",
            "93 : res4b_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f83470c1a90>\n",
            "94 : bn4b_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f83470de278>\n",
            "95 : activation_75, <keras.layers.core.Activation object at 0x7f834704c9e8>\n",
            "96 : res4b_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f8346fc2f28>\n",
            "97 : bn4b_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f8346f80b70>\n",
            "98 : activation_76, <keras.layers.core.Activation object at 0x7f8346f9f358>\n",
            "99 : res4b_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f8346e82278>\n",
            "100 : bn4b_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f8346e9e780>\n",
            "101 : add_25, <keras.layers.merge.Add object at 0x7f8346e51f60>\n",
            "102 : activation_77, <keras.layers.core.Activation object at 0x7f8346dd45c0>\n",
            "103 : res4c_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f8346d45a90>\n",
            "104 : bn4c_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f8346d65278>\n",
            "105 : activation_78, <keras.layers.core.Activation object at 0x7f8346cd19e8>\n",
            "106 : res4c_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f8346c46e48>\n",
            "107 : bn4c_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f8346c03b00>\n",
            "108 : activation_79, <keras.layers.core.Activation object at 0x7f8346c24208>\n",
            "109 : res4c_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f8346b07278>\n",
            "110 : bn4c_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f8346b23780>\n",
            "111 : add_26, <keras.layers.merge.Add object at 0x7f8346ac3518>\n",
            "112 : activation_80, <keras.layers.core.Activation object at 0x7f8346a59c88>\n",
            "113 : res4d_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f83469c9a58>\n",
            "114 : bn4d_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f83469e6240>\n",
            "115 : activation_81, <keras.layers.core.Activation object at 0x7f834695b9b0>\n",
            "116 : res4d_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f83468c93c8>\n",
            "117 : bn4d_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f8346886470>\n",
            "118 : activation_82, <keras.layers.core.Activation object at 0x7f83468a5208>\n",
            "119 : res4d_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f8346786240>\n",
            "120 : bn4d_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f83467a3c88>\n",
            "121 : add_27, <keras.layers.merge.Add object at 0x7f8346748748>\n",
            "122 : activation_83, <keras.layers.core.Activation object at 0x7f83466dc518>\n",
            "123 : res4e_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f8346649a20>\n",
            "124 : bn4e_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f83466666d8>\n",
            "125 : activation_84, <keras.layers.core.Activation object at 0x7f83465dc438>\n",
            "126 : res4e_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f83465497b8>\n",
            "127 : bn4e_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f8346506ac8>\n",
            "128 : activation_85, <keras.layers.core.Activation object at 0x7f8346525198>\n",
            "129 : res4e_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f834640c208>\n",
            "130 : bn4e_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f8346426710>\n",
            "131 : add_28, <keras.layers.merge.Add object at 0x7f83463c74a8>\n",
            "132 : activation_86, <keras.layers.core.Activation object at 0x7f834635ffd0>\n",
            "133 : res4f_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f83462c99e8>\n",
            "134 : bn4f_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f83462ea1d0>\n",
            "135 : activation_87, <keras.layers.core.Activation object at 0x7f834625ef60>\n",
            "136 : res4f_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f83461cc780>\n",
            "137 : bn4f_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f8346189400>\n",
            "138 : activation_88, <keras.layers.core.Activation object at 0x7f83461a9198>\n",
            "139 : res4f_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f834608c1d0>\n",
            "140 : bn4f_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f83460a8d68>\n",
            "141 : add_29, <keras.layers.merge.Add object at 0x7f8346048550>\n",
            "142 : activation_89, <keras.layers.core.Activation object at 0x7f8345fe04e0>\n",
            "143 : res5a_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f8345f4d9b0>\n",
            "144 : bn5a_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f8345f6d828>\n",
            "145 : activation_90, <keras.layers.core.Activation object at 0x7f8345ee2400>\n",
            "146 : res5a_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f8345e4e748>\n",
            "147 : bn5a_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f8345e0a3c8>\n",
            "148 : activation_91, <keras.layers.core.Activation object at 0x7f8345e2d160>\n",
            "149 : res5a_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f8345d11198>\n",
            "150 : res5a_branch1, <keras.layers.convolutional.Conv2D object at 0x7f8345ccb438>\n",
            "151 : bn5a_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f8345d2c6a0>\n",
            "152 : bn5a_branch1, <keras.layers.normalization.BatchNormalization object at 0x7f8345c34f98>\n",
            "153 : add_30, <keras.layers.merge.Add object at 0x7f8345bcf6d8>\n",
            "154 : activation_92, <keras.layers.core.Activation object at 0x7f8345b22080>\n",
            "155 : res5b_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f8345af0d68>\n",
            "156 : bn5b_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f8345a93cc0>\n",
            "157 : activation_93, <keras.layers.core.Activation object at 0x7f83459febe0>\n",
            "158 : res5b_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f8345995438>\n",
            "159 : bn5b_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f83459ae6d8>\n",
            "160 : activation_94, <keras.layers.core.Activation object at 0x7f834594da90>\n",
            "161 : res5b_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f83458b1748>\n",
            "162 : bn5b_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f834584ff28>\n",
            "163 : add_31, <keras.layers.merge.Add object at 0x7f8345872d68>\n",
            "164 : activation_95, <keras.layers.core.Activation object at 0x7f83457a4080>\n",
            "165 : res5c_branch2a, <keras.layers.convolutional.Conv2D object at 0x7f8345772d68>\n",
            "166 : bn5c_branch2a, <keras.layers.normalization.BatchNormalization object at 0x7f8345714400>\n",
            "167 : activation_96, <keras.layers.core.Activation object at 0x7f8345681be0>\n",
            "168 : res5c_branch2b, <keras.layers.convolutional.Conv2D object at 0x7f8345618400>\n",
            "169 : bn5c_branch2b, <keras.layers.normalization.BatchNormalization object at 0x7f8345631908>\n",
            "170 : activation_97, <keras.layers.core.Activation object at 0x7f83455d15c0>\n",
            "171 : res5c_branch2c, <keras.layers.convolutional.Conv2D object at 0x7f83455346d8>\n",
            "172 : bn5c_branch2c, <keras.layers.normalization.BatchNormalization object at 0x7f83454d3d68>\n",
            "173 : add_32, <keras.layers.merge.Add object at 0x7f83454f8cf8>\n",
            "174 : activation_98, <keras.layers.core.Activation object at 0x7f83454220f0>\n",
            "175 : global_average_pooling2d_2, <keras.layers.pooling.GlobalAveragePooling2D object at 0x7f83453d8668>\n",
            "176 : dense_2, <keras.layers.core.Dense object at 0x7f8344e68da0>\n",
            "177 : dense_2__activation__, <keras.layers.core.Activation object at 0x7f834466fe10>\n",
            "CoreML model saved\n",
            "Found 437 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b39eedaa8051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodelFitGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNetModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msaveCoreMLModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNetModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNetModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-de20a27183f4>\u001b[0m in \u001b[0;36mprint_predictions\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    134\u001b[0m         batch_size=437, class_mode='categorical', classes=['Benign', 'Healthy', 'Cancer'])\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 install -U scikit-learn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             verbose=verbose)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \"\"\"\n\u001b[0;32m-> 1268\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_2 to have shape (64, 64, 3) but got array with shape (224, 224, 3)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9cjWDuF26Tf9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "777292b6-d0b3-4f3d-f279-af3a3096150a"
      },
      "cell_type": "code",
      "source": [
        "    print_predictions(ResNetModel)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 437 images belonging to 3 classes.\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.20.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.2.1)\n",
            "Confusion matrix, without normalization\n",
            "[[56 42 54]\n",
            " [46 42 59]\n",
            " [34 47 57]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEYCAYAAAAqD/ElAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOedKkic/51xJ+n/aL0TAO56P8wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mWk0GAM_vjZ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**FINE TUNING OF RESNET18**"
      ]
    },
    {
      "metadata": {
        "id": "Kf0k0l58vl_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0M9-VVvXttbe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**VGG16 FROM GITHUB** https://github.com/flyyufelix/cnn_finetune/blob/master/vgg16.py"
      ]
    },
    {
      "metadata": {
        "id": "S3A5fDx6t19e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "\n",
        "def vgg16_model(img_rows, img_cols, channel=1, num_classes=None):\n",
        "    \"\"\"VGG 16 Model for Keras\n",
        "    Model Schema is based on \n",
        "    https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
        "    ImageNet Pretrained Weights \n",
        "    https://drive.google.com/file/d/0Bz7KyqmuGsilT0J5dmRCM0ROVHc/view?usp=sharing\n",
        "    Parameters:\n",
        "      img_rows, img_cols - resolution of inputs\n",
        "      channel - 1 for grayscale, 3 for color \n",
        "      num_classes - number of categories for our classification task\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D((1, 1), input_shape=(img_rows, img_cols, channel)))\n",
        "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1, 1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
        "\n",
        "    # Add Fully Connected Layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1000, activation='softmax'))\n",
        "\n",
        "    # Truncate and replace softmax layer for transfer learning\n",
        "    model.layers.pop()\n",
        "    model.outputs = [model.layers[-1].output]\n",
        "    model.layers[-1].outbound_nodes = []\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Uncomment below to set the first 10 layers to non-trainable (weights will not be updated)\n",
        "    for layer in model.layers[:10]:\n",
        "        layer.trainable = False\n",
        "        \n",
        "    # Loads ImageNet pre-trained data\n",
        "    weights_model='/content/gdrive/My Drive/Bioinformatica/vgg16_weights.h5'\n",
        "    model.load_weights(weights_model, by_name=True)\n",
        "\n",
        "    # Learning rate is changed to 0.001\n",
        "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XDFyIq3OuFgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Training/Patches\"\n",
        "valid_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Validation/Patches\"\n",
        "test_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Test/Patches\" \n",
        "  \n",
        "modelX = vgg16_model(224, 224, 3, 3)\n",
        "\n",
        "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)\n",
        "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)\n",
        "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)\n",
        "  \n",
        "# Start Fine-tuning\n",
        "modelX.fit_generator(train_batches,\n",
        "                    steps_per_epoch=train_batches.samples/train_batches.batch_size ,\n",
        "                    epochs=15,\n",
        "                    validation_data=valid_batches,\n",
        "                    validation_steps=valid_batches.samples/valid_batches.batch_size,\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SeKlgkfufrHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "40abeba8-b7c4-497e-dc4b-18d64316d6e7"
      },
      "cell_type": "code",
      "source": [
        "#PROVA PER LEGGERE E SALVARE IN PNG LA MAP ... FUNZIONA ANCHE SE NON è ALLA MASSIMA DIMENSIONE\n",
        "\n",
        "!apt install openslide-tools\n",
        "!pip install openslide-python\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import openslide\n",
        "\n",
        "slide = openslide.OpenSlide('/content/gdrive/My Drive/Bioinformatica/map_1.svs')\n",
        "\n",
        "print(\"total image size: x=%d y=%d\" % slide.dimensions)\n",
        "\n",
        "\n",
        "\n",
        "# read_region return an RGBA image containing the content of the specified region.\n",
        "\n",
        "img = slide.read_region((255,255), slide.level_count-1, (5000, 5000)) # ((x,y) = start region, 0 = level, (x,y) = size)\n",
        "img.save('/content/gdrive/My Drive/Bioinformatica/TestMap.png',format='png')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openslide-tools is already the newest version (3.4.1+dfsg-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n",
            "Requirement already satisfied: openslide-python in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from openslide-python) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->openslide-python) (0.46)\n",
            "total image size: x=41000 y=25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YRPbLklaiMhI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "visualize_class_activation_map('/content/gdrive/My Drive/Bioinformatica/newVGG16.h5','/content/gdrive/My Drive/Bioinformatica/TestMap.png','/content/gdrive/My Drive/Bioinformatica/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qykcvrqF2OXi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**LA CLASS ACTIVACTION MAP SENZA NON FUNZIONARE PER VIA DI UN ERRORE (COME SI LEGGE QUI SOPRA) CHE NON SO CAPIRE**"
      ]
    },
    {
      "metadata": {
        "id": "JVE-EFpr7RU0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**LINK UTILE PER SPEZZETTARE LE IMMAGINI, COLORARLE A SECONDA DELLA PREDICTION E POI RIUNIRLE: ** http://www.andrewjanowczyk.com/dividing-and-re-merging-large-images-humpty-dumpty/ (è scritto per Matlab, bisognerebbe adattarlo per Python, c'è questo tool utile per la conversione, dovesse servire https://github.com/victorlei/smop)"
      ]
    },
    {
      "metadata": {
        "id": "mUny3oQZ7o5O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tileSize = [2000, 2000]; % has to be a multiple of 16.\n",
        " \n",
        "input_svs_page=3; %the page of the svs file we're interested in loading\n",
        "input_svs_file='36729.svs';\n",
        "[~,baseFilename,~]=fileparts(input_svs_file);\n",
        " \n",
        "svs_adapter =PagedTiffAdapter(input_svs_file,input_svs_page); %create an adapter which modulates how the large svs file is accessed\n",
        " \n",
        "tic\n",
        "fun=@(block) imwrite(block.data,sprintf('%s_%d_%d.png',baseFilename,block.location(1),block.location(2))); %make a function which saves the individual tile with the row/column information in the filename so that we can refind this tile later\n",
        "blockproc(svs_adapter,tileSize,fun); %perform the splitting\n",
        "toc\n",
        "\n",
        "tic\n",
        "outFile='36729.tif'; %desired output filename\n",
        "inFileInfo=imfinfo(input_svs_file); %need to figure out what the final output size should be to create the emtpy tif that will be filled in\n",
        "inFileInfo=inFileInfo(input_svs_page); %imfinfo returns a struct for each individual page, we again select the page we're interested in\n",
        " \n",
        "outFileWriter = bigTiffWriter(outFile, inFileInfo.Height, inFileInfo.Width, tileSize(1), tileSize(1),true); %create another image adapter for output writing\n",
        " \n",
        "fun=@(block) imresize(repmat(imread(sprintf('%s_%d_%d_prob.png',baseFilename,block.location(1),block.location(2))),[1 1 3]),1.666666666); %load the output image, which has an expected filename (the two locations added). In this case my output is 60% smaller than the original image, so i'll scale it back up\n",
        " \n",
        "blockproc(svs_adapter,tileSize,fun,'Destination',outFileWriter); %do the blockproc again, which will result in the same row/column coordinates, except now we specify the output image adatper to write the flie outwards\n",
        " \n",
        "outFileWriter.close(); %close the file when we're done\n",
        "toc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-cTS-CL9F0I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#PER VEDERE GLI ERRORI DI PREDIZIONE SULLE IMMAGINI STESS PUò ESSERE ADATTATO PER VEDERE QUALE PREDICTION CORRISPONDE A QUALE IMMAGINE\n",
        "\n",
        "# Get the filenames from the generator\n",
        "fnames = validation_generator.filenames\n",
        " \n",
        "# Get the ground truth from generator\n",
        "ground_truth = validation_generator.classes\n",
        " \n",
        "# Get the label to class mapping from the generator\n",
        "label2index = validation_generator.class_indices\n",
        " \n",
        "# Getting the mapping from class index to class label\n",
        "idx2label = dict((v,k) for k,v in label2index.items())\n",
        " \n",
        "# Get the predictions from the model using the generator\n",
        "predictions = model.predict_generator(validation_generator, steps=validation_generator.samples/validation_generator.batch_size,verbose=1)\n",
        "predicted_classes = np.argmax(predictions,axis=1)\n",
        " \n",
        "errors = np.where(predicted_classes != ground_truth)[0]\n",
        "print(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))\n",
        " \n",
        "# Show the errors\n",
        "for i in range(len(errors)):\n",
        "    pred_class = np.argmax(predictions[errors[i]])\n",
        "    pred_label = idx2label[pred_class]\n",
        "     \n",
        "    title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
        "        fnames[errors[i]].split('/')[0],\n",
        "        pred_label,\n",
        "        predictions[errors[i]][pred_class])\n",
        "     \n",
        "    original = load_img('{}/{}'.format(validation_dir,fnames[errors[i]]))\n",
        "    plt.figure(figsize=[7,7])\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    plt.imshow(original)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}