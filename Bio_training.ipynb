{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bio_training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marel88/Bioinfo_7_1/blob/master/Bio_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LzELL8aM7GgM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**FOR GOOGLE DRIVE IMPORT**"
      ]
    },
    {
      "metadata": {
        "id": "u3ONVKn-7eZI",
        "colab_type": "code",
        "outputId": "b0971d27-73e6-4029-b428-2c83d4b176ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G0EP9-6VtU73",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DATASET PRE PROCESSING**"
      ]
    },
    {
      "metadata": {
        "id": "H4oUSSOuy7VP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install py_wsi --no-index --find-links file:///Users/Mac/Desktop/py-wsi-1.1.zip\n",
        "!apt install openslide-tool\n",
        "!pip install openslide-python\n",
        "\n",
        "#SCRIPT FOR IMAGE CROPPING\n",
        "\n",
        "\n",
        "import py_wsi\n",
        "import py_wsi.imagepy_toolkit as tk\n",
        "from py_wsi import turtle\n",
        "\n",
        "file_dir = \"/Users/Mac/Desktop/ROI-dataset-bioinf/Training/Healthy/\"\n",
        "db_location = \"/Users/Mac/Desktop/ROI-dataset-bioinf/Training/Healthy_patches/\"\n",
        "xml_dir = file_dir\n",
        "patch_size = 64\n",
        "level = 10\n",
        "db_name = \"\"\n",
        "overlap = 0\n",
        "\n",
        "# All possible labels mapped to integer ids in order of increasing severity.\n",
        "label_map = {}\n",
        "\n",
        "turtle = turtle.Turtle(file_dir, db_location, db_name, xml_dir=xml_dir, label_map=label_map, storage_type='disk')\n",
        "turtle.sample_and_store_patches(patch_size, level, overlap, load_xml=False, limit_bounds=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XaISfS_fvzVz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**SCRIPT FOR ERASING ONLY WHITE IMAGES**"
      ]
    },
    {
      "metadata": {
        "id": "fuEFrnvMv5bi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#the function for deleting white patches\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def deleteWhite(path):                                              #path is the path of the Patches folder\n",
        "    \"\"\"Function that deletes all patches that are completely (or mostly) white.\"\"\"\n",
        "\n",
        "    folders = [path + \"/Healthy\", path + \"/Benign\", path + \"/Cancer\"]\n",
        "    for folder in folders:                                          #loops through the three folders of patches\n",
        "        count = 0\n",
        "        for filename in glob.glob(os.path.join(folder, '*.png')):   #sequentially selects each .png file in the current folder\n",
        "            img = cv2.imread(filename)\n",
        "            (x,y,z) = img.shape                                     #img.shap is 64 64 3\n",
        "            white = 0\n",
        "            for i in range(0,x):                                    #analyzes the image pixel by pixel\n",
        "                for j in range(0,y):\n",
        "                    pixel = img[i,j]\n",
        "                    b = pixel[0]\n",
        "                    g = pixel[1]\n",
        "                    r = pixel[2]\n",
        "                    if b == 255:                                    #if b,g,r are all 255 it means the pixel is white\n",
        "                        if g == 255:\n",
        "                            if r == 255:\n",
        "                                white = white + 1                   #I use white as a counter to keep track of the number of white pixels\n",
        "                    if white > 50:                                  #in the dataset that we have, an image having a few white pixels means it will be almost all white\n",
        "                        break                                       #thus to make the process a bit shorter I only count to 50 white pixels and then break the loop, since it is unneded to count further\n",
        "                if white > 50:\n",
        "                    break\n",
        "            if white > 50:                                          #if a patch is found to have many white pixels (which means it will be mostly white) I delete it from its folder\n",
        "                os.remove(filename)\n",
        "                count = count + 1\n",
        "        print(\"Deleted\",count,\"patches in\",folder)\n",
        "\n",
        "    return;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b44RtPXH6tkR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#LOOP TO CLEAN UP FOLDERS\n",
        "\n",
        "main_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset\"\n",
        "main_folders = [main_path + \"/Test/Patches\", main_path + \"/Training/Patches\", main_path + \"/Validation/Patches\"]\n",
        "for main_folder in main_folders:\n",
        "    new_path = main_folder\n",
        "    deleteWhite(new_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eiShUK7CtamG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CNN BASE**"
      ]
    },
    {
      "metadata": {
        "id": "g3BQ4dD9unk5",
        "colab_type": "code",
        "outputId": "fccdee12-df87-4c00-eb9d-6eb6449c2006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "cell_type": "code",
      "source": [
        "#CNN BASE MODEL - DATA LOADING\n",
        "\n",
        "import numpy as np\n",
        "!pip3 install keras\n",
        "#!pip3 install tensorflow==1.5.0\n",
        "!pip3 install tensorflow\n",
        "!pip install mxnet-mkl\n",
        "!pip3 install sklearn\n",
        "!pip3 install keras_tqdm\n",
        "!pip install scipy\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import *\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.2.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.9)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.9.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: mxnet-mkl in /usr/local/lib/python3.6/dist-packages (1.4.0.post0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (0.8.4)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (2.21.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (3.0.4)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n",
            "Requirement already satisfied: keras_tqdm in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (2.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.11.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "NaQkjeNR7MnV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Training/Patches\"\n",
        "#train_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Training/Patches/\"\n",
        "valid_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Validation/Patches\"\n",
        "#valid_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Patches\"\n",
        "#test_path =\"/Users/Mac/Desktop/ROI-dataset-bioinf/Test/Patches\"\n",
        "test_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Test/Patches\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UzyWGHvlC_Fb",
        "colab_type": "code",
        "outputId": "2632cc06-4f2d-48fe-802d-841c2c4e55a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)\n",
        "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)\n",
        "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3306 images belonging to 3 classes.\n",
            "Found 1589 images belonging to 3 classes.\n",
            "Found 765 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5RLPLu5mmhGj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For plotting images with labels\n",
        "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NyJOfCvIVQWS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imgs, labels = next(train_batches)\n",
        "\n",
        "#plots(imgs,titles=labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QBTKs_NaVR86",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CNN MODEL BUILDING\n",
        "model = Sequential([Conv2D(32,(3,3),activation='relu',input_shape=(64,64,3)), Flatten(), Dense(3, activation='softmax'),])\n",
        "model.compile(Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit_generator(train_batches, steps_per_epoch=22, validation_data=valid_batches, validation_steps=22, epochs=5, verbose=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97pjhfx3WmVq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_imgs, test_labels = next(test_batches)\n",
        "plots(test_imgs, titles = test_labels)\n",
        "#test_labels = test_labels[:,0]\n",
        "test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DMrMcizcaTrF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict_generator(test_batches, steps=1, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ze9ZQv93dGX0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sMFD6PUqdIHM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -U scikit-learn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(test_labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yB1x83jJb8N8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#MULTI-LABEL CONFUSION MATRIX\n",
        "\n",
        "y_test_non_category = [ np.argmax(t) for t in test_labels ]\n",
        "y_predict_non_category = [ np.argmax(t) for t in predictions ]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(y_test_non_category, y_predict_non_category)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f-e8J4TceQl-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "#This function prints and plots the confusion matrix.\n",
        "#Normalization can ben applied by setting 'normalize-True'\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks=np.arange(len(classes))\n",
        "    plt.xticks(tick_marks,classes,rotation=45)\n",
        "    plt.yticks(tick_marks,classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2\n",
        "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "           plt.text(j, i, \"{:0.2f}\".format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "        else:\n",
        "           plt.text(j, i, format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RzLMUdm-keV_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm_plot_labels = ['Benign','Healthy','Cancer']\n",
        "plot_confusion_matrix(conf_mat, cm_plot_labels,title ='Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kPrSiv3lmHC3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**FIN QUI TUTTO OK, IL MODELLO FA SCHIFO MA TECNICAMENTE FA QUELLO CHE DEVE FARE, SE LA CONFUSION MATRIX È GIUSTA, HO TROVATO COME PLOTTARLA CON UN MODELLO A MULTI LABEL**"
      ]
    },
    {
      "metadata": {
        "id": "dH8ZmCrhtf1j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**FINE TUNING OF VGG16** "
      ]
    },
    {
      "metadata": {
        "id": "024xq-WbmSqU",
        "colab_type": "code",
        "outputId": "57e51adb-9154-44a8-8c29-8b900cb4dccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "cell_type": "code",
      "source": [
        "#FINE TUNING OF A PRE-TRAINED MODEL (VGG16)\n",
        "\n",
        "import numpy as np\n",
        "!pip3 install keras\n",
        "#!pip3 install tensorflow==1.5.0\n",
        "!pip3 install tensorflow\n",
        "!pip install mxnet-mkl\n",
        "!pip3 install sklearn\n",
        "!pip3 install keras_tqdm\n",
        "!pip install scipy\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import *\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "vgg16_model = keras.applications.vgg16.VGG16()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.2.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.7)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.2)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: mxnet-mkl in /usr/local/lib/python3.6/dist-packages (1.4.0.post0)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (2.21.0)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (1.14.6)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (0.8.4)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2.6)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n",
            "Requirement already satisfied: keras_tqdm in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (4.28.1)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (2.2.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.2.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.9)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.14.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.11.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LKxIhkFQpEoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vgg16_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e0LtghsxzICS",
        "colab_type": "code",
        "outputId": "3513d27b-0da3-4890-f479-22d970ae7f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "train_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Training/Patches\"\n",
        "#train_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Training/Patches/\"\n",
        "valid_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Validation/Patches\"\n",
        "#valid_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Patches\"\n",
        "#test_path =\"/Users/Mac/Desktop/ROI-dataset-bioinf/Test/Patches\"\n",
        "test_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Test/Patches\"\n",
        "\n",
        "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)\n",
        "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)\n",
        "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['Benign', 'Healthy', 'Cancer'], batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3306 images belonging to 3 classes.\n",
            "Found 1589 images belonging to 3 classes.\n",
            "Found 765 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0rV5hG5K1ftf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(vgg16_model)\n",
        "#create a Sequential model in which we add all the layers of the VGG16 model\n",
        "model = Sequential()\n",
        "for layer in vgg16_model.layers[:-1]:\n",
        "  #all layers except for the last one which is the predictions layers we don't want\n",
        "    model.add(layer)\n",
        "    \n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e_uGdPHX2kX9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JI2uQhG_Cfiv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95lCz-aEDjZc",
        "colab_type": "code",
        "outputId": "e9506168-8c32-43ff-f5fc-35bf1f74b807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1306
        }
      },
      "cell_type": "code",
      "source": [
        "#TRAIN THE VGG16 MODEL\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=2,\n",
        "                              verbose=0, mode='auto')\n",
        "#lr=0.001\n",
        "#steps per epoch and validation step = dataset size / batch size\n",
        "model.compile(Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), loss ='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit_generator(train_batches, steps_per_epoch=33, validation_data=valid_batches, validation_steps=33, epochs=30, verbose=2, callbacks=[es])\n",
        "model.save('/content/gdrive/My Drive/Bioinformatica/FirstVGG16.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/30\n",
            " - 17s - loss: 0.9682 - acc: 0.5956 - val_loss: 0.7139 - val_acc: 0.7008\n",
            "Epoch 2/30\n",
            " - 12s - loss: 0.5085 - acc: 0.7955 - val_loss: 0.5527 - val_acc: 0.8029\n",
            "Epoch 3/30\n",
            " - 10s - loss: 0.3801 - acc: 0.8570 - val_loss: 0.4620 - val_acc: 0.8314\n",
            "Epoch 4/30\n",
            " - 12s - loss: 0.3438 - acc: 0.8614 - val_loss: 0.4994 - val_acc: 0.8182\n",
            "Epoch 5/30\n",
            " - 11s - loss: 0.2661 - acc: 0.9100 - val_loss: 0.4355 - val_acc: 0.8593\n",
            "Epoch 6/30\n",
            " - 11s - loss: 0.2896 - acc: 0.8873 - val_loss: 0.4448 - val_acc: 0.8494\n",
            "Epoch 7/30\n",
            " - 10s - loss: 0.2556 - acc: 0.9081 - val_loss: 0.4098 - val_acc: 0.8679\n",
            "Epoch 8/30\n",
            " - 10s - loss: 0.2362 - acc: 0.9100 - val_loss: 0.3831 - val_acc: 0.8813\n",
            "Epoch 9/30\n",
            " - 10s - loss: 0.2270 - acc: 0.9100 - val_loss: 0.4588 - val_acc: 0.8466\n",
            "Epoch 10/30\n",
            " - 10s - loss: 0.2395 - acc: 0.9052 - val_loss: 0.3914 - val_acc: 0.8641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7050f72fe1e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'content/gdrive/My Drive/Bioinformatica/FirstVGG16.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'content/gdrive/My Drive/Bioinformatica/FirstVGG16.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Pw21Fbc0HlpT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/My Drive/Bioinformatica/FirstVGG16.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1iEgYFqaJory",
        "colab_type": "code",
        "outputId": "5ec7d42e-0156-401e-c459-641191bf437f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_imgs, test_labels = next(test_batches)\n",
        "len(test_labels)\n",
        "#plots(test_imgs, titles = test_labels)\n",
        "#test_labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "16yYjozTaS3Q",
        "colab_type": "code",
        "outputId": "d8497176-3931-470d-dcfa-3faba6766a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#steps = images in the test folder / batch size\n",
        "predictions = model.predict_generator(test_batches, steps= 1, verbose=0)\n",
        "len(predictions)\n",
        "#predictions = np.argmax(predictions, axis=-1) #multiple categories"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "IevjxPbdz42F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "#This function prints and plots the confusion matrix.\n",
        "#Normalization can ben applied by setting 'normalize-True'\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks=np.arange(len(classes))\n",
        "    plt.xticks(tick_marks,classes,rotation=45)\n",
        "    plt.yticks(tick_marks,classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2\n",
        "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "           plt.text(j, i, \"{:0.2f}\".format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "        else:\n",
        "           plt.text(j, i, format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lXWPqShJahcX",
        "colab_type": "code",
        "outputId": "5860fbc4-65ac-4ea9-8c0a-e29a0e34e4f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -U scikit-learn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#cm = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "#MULTI-LABEL CONFUSION MATRIX\n",
        "\n",
        "y_test_non_category = [ np.argmax(t) for t in test_labels ]\n",
        "#y_test_non_category = np.argmax(test_labels, axis=-1) #multiple categories\n",
        "y_predict_non_category = [ np.argmax(t) for t in predictions ]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(y_test_non_category, y_predict_non_category)\n",
        "\n",
        "cm_plot_labels = ['Benign','Healthy','Cancer']\n",
        "plot_confusion_matrix(conf_mat,cm_plot_labels,normalize=False,title ='Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.20.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.2.1)\n",
            "Confusion matrix, without normalization\n",
            "[[ 2  6  2]\n",
            " [ 2 14  1]\n",
            " [ 1  3  1]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEmCAYAAADmw8JdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAKcbbgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oImJd6lZeHIx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ebt5IeUAbJGI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**QUESTA DOVREBBE ESSERE LA FINE DELLA PRIMA PARTE DI TEST, SE FIN QUI I RISULTATI SONO BUONI, POSSIAMO FERMARCI SE NO BISOGNA FARE DATA AUGMENTATION E AUMENTARE LE EPOCHS**"
      ]
    },
    {
      "metadata": {
        "id": "K8dBilwSbHUR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#DATA AUGMENATION\n",
        "\n",
        "#NOTE: every time this script is run, image crops will augment of a 6 factor\n",
        "\n",
        "gen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, channel_shift_range=10., horizontal_flip=True)\n",
        "\n",
        "path=\"/content/gdrive/My Drive/Bioinformatica/Patches\"\n",
        "\n",
        "folders = [path + \"/Healthy\", path + \"/Benign\", path + \"/Cancer\"]\n",
        "for folder in folders:                                          #loops through the three folders of patches\n",
        "   for filename in glob.glob(os.path.join(folder, '*.png')):   #sequentially selects each .png file in the current folder\n",
        "      print(filename)\n",
        "      image = np.expand_dims(ndimage.imread(filename),0)\n",
        "      aug_iter = gen.flow(image)\n",
        "      aug_image = [next(aug_iter)[0].astype(np.uint8) for i in range(6)]  #get 6 samples of augmented images\n",
        "      for i in range(len(aug_image)):                                     #save all the generated images\n",
        "        scipy.misc.imsave(filename[:-4] + str(i) + '.png', aug_image[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ddwqK8VM3M8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7s1uj2ZKRIRi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mIb3_hoZRZd3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-HvKA8JYRhCf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDHtej_pRtX3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9gMCxAa6Pky9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**SE I RISULTATI OTTENUTI CON UN DETERMINATO SET DI IMPOSTAZIONI SONO BUONI E VOGLIAMO FREEZZARLI E RIPRODURLI ...**"
      ]
    },
    {
      "metadata": {
        "id": "Wf1Il5dSPwvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as rn\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "#Setting the seed for numpy-generated random numbers\n",
        "np.random.seed(37)\n",
        "\n",
        "#Setting the seed for Python random numbers\n",
        "rn.seed(1254)\n",
        "\n",
        "#Setting the seed for Tensorflow random numbers\n",
        "tf.set_random_seed(89)\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "#Force TensorFlow to use a single thread\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "#Paste training Keras code here after setting the random seeds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hzocYylhSBvu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **CLASS ACTIVION MAP**"
      ]
    },
    {
      "metadata": {
        "id": "_u4vOjUh_zfO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# --- CLASS ACTIVATION MAP --- #\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "import keras.backend as K\n",
        "from model import *\n",
        "from data import *\n",
        "import cv2\n",
        "\n",
        "#After the last convolutional layer in a typical network like VGG16, we have an N-dimensional image, where N is the number of filters in this layer. \n",
        "#For example in VGG16, the last convolutional layer has 512 filters. For example, for an 1024x1024 input image (lets discard the fully connected layers, \n",
        "#so we can use any input image size we want), the output shape of the last convolutional layer will be 512x64x64. \n",
        "#Since 1024/64 = 16, we have a 16x16 spatial mapping resolution. \n",
        "#A global average pooling (GAP) layer just takes each of these 512 channels, and returns their spatial average. \n",
        "#Channels with high activations, will have high signals.\n",
        "\n",
        "def global_average_pooling(x):\n",
        "        return K.mean(x, axis = (2, 3))\n",
        "  \n",
        "\n",
        "def global_average_pooling_shape(input_shape):\n",
        "        return input_shape[0:2]\n",
        "  \n",
        "#The second step is to assign a weight to each output from the global average pooling layer, for each of the categories. \n",
        "#This can be done by adding a dense linear layer + softmax, training an SVM on the GAP output, or applying any other linear classifier on top of the GAP. \n",
        "#These weights set the importance of each of the convolutional layer outputs.\n",
        "\n",
        "\n",
        "#TO DO: \n",
        "#    --- definire una funzione che crei il modello VGG16 (ho visto che Elena ha creato il modello ma non dentro una funzione)\n",
        "def get_model():\n",
        "\t    model = VGG16_convolutions()\n",
        "\t    model = load_model_weights(model, \"vgg16_weights.h5\")\n",
        "\t    \n",
        "\t    model.add(Lambda(global_average_pooling, \n",
        "\t              output_shape=global_average_pooling_shape))\n",
        "\t    model.add(Dense(2, activation = 'softmax', init='uniform'))\n",
        "\t    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.5, nesterov=True)\n",
        "\t    model.compile(loss = 'categorical_crossentropy', \\\n",
        "            optimizer = sgd, metrics=['accuracy'])\n",
        "\t    return model\n",
        "\n",
        "def load_model_weights(model, weights_path):\n",
        "    print 'Loading model.'\n",
        "    f = h5py.File(weights_path)\n",
        "    for k in range(f.attrs['nb_layers']):\n",
        "        if k >= len(model.layers):\n",
        "            # we don't look at the last (fully-connected) layers in the savefile\n",
        "            break\n",
        "        g = f['layer_{}'.format(k)]\n",
        "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
        "        model.layers[k].set_weights(weights)\n",
        "        model.layers[k].trainable = False\n",
        "    f.close()\n",
        "    print 'Model loaded.'\n",
        "    return model\n",
        "\n",
        "def get_output_layer(model, layer_name):\n",
        "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "    layer = layer_dict[layer_name]\n",
        "    return layer    \n",
        "       \n",
        "#TO DO: \n",
        "# --- definire il \"dataset_path\"\n",
        "# --- definire la funzione \"load_images\": è necessario creare due path diversi, uno per immagini positive e l'altro per quelle negative\n",
        "#     (poi la faccio io appena riusciamo a fare i test)\n",
        "\n",
        "def train(dataset_path):\n",
        "        model = get_model()\n",
        "        X, y = load_images(dataset_path)\n",
        "\t      print \"Training..\"\n",
        "        checkpoint_path=\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
        "        checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto')\n",
        "        model.fit(X, y, nb_epoch=40, batch_size=32, validation_split=0.2, verbose=1, callbacks=[checkpoint])\n",
        "\n",
        "#Now to create a heatmap for a class we can just take output images from the last convolutional layer, multiply them by their assigned weights \n",
        "#(different weights for each class), and sum.\n",
        "\n",
        "def visualize_class_activation_map(model_path, img_path, output_path):\n",
        "        model = load_model(model_path)\n",
        "        original_img = cv2.imread(img_path, 1)\n",
        "        width, height, _ = original_img.shape\n",
        "\n",
        "        #Reshape to the network input shape (3, w, h).\n",
        "        img = np.array([np.transpose(np.float32(original_img), (2, 0, 1))])\n",
        "        \n",
        "        #Get the 512 input weights to the softmax.\n",
        "        class_weights = model.layers[-1].get_weights()[0]\n",
        "        final_conv_layer = get_output_layer(model, \"conv5_3\")\n",
        "        get_output = K.function([model.layers[0].input], \\\n",
        "                    [final_conv_layer.output, \n",
        "        model.layers[-1].output])\n",
        "        [conv_outputs, predictions] = get_output([img])\n",
        "        conv_outputs = conv_outputs[0, :, :, :]\n",
        "\n",
        "        #Create the class activation map.\n",
        "        cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])\n",
        "        target_class = 1\n",
        "        for i, w in enumerate(class_weights[:, target_class]):\n",
        "                cam += w * conv_outputs[i, :, :]\n",
        "        print \"predictions\", predictions\n",
        "        cam /= np.max(cam)\n",
        "        cam = cv2.resize(cam, (height, width))\n",
        "        heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
        "        heatmap[np.where(cam < 0.2)] = 0\n",
        "        img = heatmap*0.5 + original_img\n",
        "        cv2.imwrite(output_path, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BVh5rtuAJzoe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**ANOTHER FINE TUNING OF VGG16**"
      ]
    },
    {
      "metadata": {
        "id": "bZygExd5J3ed",
        "colab_type": "code",
        "outputId": "d1343a07-2dc6-424f-ac3b-53bf168caef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1312
        }
      },
      "cell_type": "code",
      "source": [
        "#NEW VGG16 TUNING\n",
        "\n",
        "import numpy as np\n",
        "!pip3 install keras\n",
        "#!pip3 install tensorflow==1.5.0\n",
        "!pip3 install tensorflow\n",
        "!pip install mxnet-mkl\n",
        "!pip3 install sklearn\n",
        "!pip3 install keras_tqdm\n",
        "!pip install scipy\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import *\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from keras.applications import VGG16\n",
        "#Load the VGG model\n",
        "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers except the last 4 layers\n",
        "for layer in vgg16_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        " \n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg16_model.layers:\n",
        "    print(layer, layer.trainable)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.7)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.2.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.9)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n",
            "Requirement already satisfied: mxnet-mkl in /usr/local/lib/python3.6/dist-packages (1.4.0.post0)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (1.14.6)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-mkl) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-mkl) (2.6)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n",
            "Requirement already satisfied: keras_tqdm in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (4.28.1)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.14.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.2.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.11.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.14.6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "<keras.engine.input_layer.InputLayer object at 0x7fb99c4b7dd8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb997729dd8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb997729fd0> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fb99708b7f0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb99708b278> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb997040588> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fb997054c50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb9970547b8> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb9970006a0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb997018eb8> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fb996fc3710> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb996fc3240> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb996f71390> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb996f879e8> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fb996f33160> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb996f9fd68> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb996f4ac88> True\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fb996ef64e0> True\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fb996f0f828> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZEsbH3OnKx1k",
        "colab_type": "code",
        "outputId": "5d4c6600-006b-4412-a6e0-913f71960dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        " \n",
        "# Create the model\n",
        "newVGG16_model = models.Sequential()\n",
        " \n",
        "# Add the vgg convolutional base model\n",
        "newVGG16_model.add(vgg16_model)\n",
        " \n",
        "# Add new layers\n",
        "newVGG16_model.add(layers.Flatten())\n",
        "newVGG16_model.add(layers.Dense(1024, activation='relu'))\n",
        "newVGG16_model.add(layers.Dropout(0.1))\n",
        "newVGG16_model.add(layers.Dense(3, activation='softmax'))\n",
        " \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "newVGG16_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 40,408,899\n",
            "Trainable params: 32,773,635\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RvbWegZuLykP",
        "colab_type": "code",
        "outputId": "1e03a4bd-6583-4a05-f1c8-b1f153d04ba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "train_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Training/Patches\"\n",
        "#train_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Training/Patches/\"\n",
        "valid_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Validation/Patches\"\n",
        "#valid_path=\"/Users/Mac/Desktop/ROI-dataset-bioinf/Validation/Patches\"\n",
        "#test_path =\"/Users/Mac/Desktop/ROI-dataset-bioinf/Test/Patches\"\n",
        "test_path=\"/content/gdrive/My Drive/Bioinformatica/Organized dataset/Test/Patches\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=20,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        " \n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        " \n",
        "# Change the batchsize according to your system RAM\n",
        "train_batchsize = 100\n",
        "val_batchsize = 10\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=train_batchsize,\n",
        "        class_mode='categorical')\n",
        " \n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        valid_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=val_batchsize,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3306 images belonging to 3 classes.\n",
            "Found 1589 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qbhBqv8hMocM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=2,\n",
        "                              verbose=0, mode='auto')\n",
        "\n",
        "# Compile the model\n",
        "newVGG16_model.compile(loss='categorical_crossentropy',optimizer=\n",
        "              Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
        "              metrics=['acc'])\n",
        "# Train the model\n",
        "history = newVGG16_model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
        "      verbose=1)#, callbacks=[es])\n",
        " \n",
        "# Save the model\n",
        "newVGG16_model.save('/content/gdrive/My Drive/Bioinformatica/newVGG16.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xsHhyqywXtMI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "newVGG16 = load_model('/content/gdrive/My Drive/Bioinformatica/newVGG16.h5')\n",
        "\n",
        "generator = ImageDataGenerator().flow_from_directory(\n",
        "        '/content/gdrive/My Drive/Bioinformatica/Organized dataset/Test/Patches',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=200)\n",
        "\n",
        "probabilities = newVGG16_model.predict_generator(generator, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UioDBSuWMAMX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "probabilities = np.argmax(probabilities, axis=-1) #multiple categories"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CPSQ2ztv0BSL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "\n",
        "#This function prints and plots the confusion matrix.\n",
        "#Normalization can ben applied by setting 'normalize-True'\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks=np.arange(len(classes))\n",
        "    plt.xticks(tick_marks,classes,rotation=45)\n",
        "    plt.yticks(tick_marks,classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2\n",
        "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "           plt.text(j, i, \"{:0.2f}\".format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "        else:\n",
        "           plt.text(j, i, format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i,j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9QHDhLbHMy1p",
        "colab_type": "code",
        "outputId": "9c6cbe42-9193-4446-9ebe-c2fa016b50f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -U scikit-learn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#cm = confusion_matrix(test_labels, predictions)\n",
        "\n",
        "#MULTI-LABEL CONFUSION MATRIX\n",
        "test_dir, test_labels = next(generator)\n",
        "test_img = [ np.argmax(t) for t in test_labels ]\n",
        "#y_predict_non_category = [ np.argmax(t) for t in predictions ]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(test_img, probabilities)\n",
        "\n",
        "cm_plot_labels = ['Benign','Healthy','Cancer']\n",
        "plot_confusion_matrix(conf_mat,cm_plot_labels,normalize=False,title ='Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.20.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.2.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.14.6)\n",
            "Confusion matrix, without normalization\n",
            "[[12  2 25]\n",
            " [ 7  4 17]\n",
            " [36  9 88]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEmCAYAAADmw8JdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ03nnMvB/wNzYsbniPbbQAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2ctEn5o83EFe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**FINE TUNING RESNET50**"
      ]
    },
    {
      "metadata": {
        "id": "dHRqp23fGCzq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install h5py\n",
        "\n",
        "!pip install -U --force-reinstall --no-dependencies git+https://github.com/datumbox/keras@bugfix/trainable_bn\n",
        "#http://blog.datumbox.com/the-batch-normalization-layer-of-keras-is-broken/\n",
        "\n",
        "!pip install -U coremltools\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model,load_model\n",
        "from keras.layers import Dense,GlobalAveragePooling2D,Input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adadelta\n",
        "import keras\n",
        "import math, os, sys\n",
        "import matplotlib.pyplot as plt\n",
        "import coremltools\n",
        "\n",
        "\n",
        "\n",
        "def get_model():\n",
        "  \n",
        "    input_tensor = Input(shape=(224, 224, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
        "\n",
        "    # create the base pre-trained model\n",
        "    base_model = ResNet50(input_tensor=input_tensor,weights='imagenet',include_top=False)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    updatedModel = Model(base_model.input, x)\n",
        "\n",
        "    return  updatedModel\n",
        "\n",
        "\n",
        "\n",
        "def compile_model(compiledModel):\n",
        "\n",
        "    compiledModel.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=Adadelta(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "def modelFitGenerator(fitModel):\n",
        "\n",
        "    num_train_samples = sum([len(files) for r, d, files in os.walk(train_data_dir)])\n",
        "    num_valid_samples = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
        "\n",
        "    num_train_steps = math.floor(num_train_samples/batch_size)\n",
        "    num_valid_steps = math.floor(num_valid_samples/batch_size)\n",
        "    \n",
        "    train_datagen = ImageDataGenerator(  \n",
        "      rotation_range=90,      \n",
        "      horizontal_flip=True,    \n",
        "      vertical_flip=True,\n",
        "      zoom_range=0.4)\n",
        "\n",
        "    test_datagen = ImageDataGenerator()\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "      train_data_dir,\n",
        "      target_size=image_size ,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical', shuffle=True\n",
        "    )\n",
        "\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "      validation_data_dir,\n",
        "      target_size=image_size ,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical', shuffle=True\n",
        "    )\n",
        "\n",
        "    print(\"start history model\")\n",
        "    history = fitModel.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=num_train_steps,\n",
        "      epochs=nb_epoch,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=num_valid_steps)\n",
        "    \n",
        "    printGraph(history)\n",
        "\n",
        "def printGraph(history):\n",
        "    \n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "def saveCoreMLModel(kerasModel):\n",
        "    coreml_model = coremltools.converters.keras.convert(kerasModel,\n",
        "                                                    input_names=['input'],\n",
        "                                                    output_names=['probs'],\n",
        "                                                    image_input_names='input',\n",
        "                                                    predicted_feature_name='predictedMoney',\n",
        "                                                    class_labels = 'drive/Resnet/labels.txt')\n",
        "    coreml_model.save('resnet50custom.mlmodel') \n",
        "    print('CoreML model saved')\n",
        "    \n",
        "    \n",
        "def main():\n",
        "    model = get_model()\n",
        "    compile_model(model)\n",
        "    modelFitGenerator(model)\n",
        "    saveCoreMLModel(model)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # constants\n",
        "    image_size = (224, 224)\n",
        "    train_data_dir = 'drive/Resnet/dataset/train' \n",
        "    validation_data_dir = 'drive/Resnet/dataset/test'\n",
        "    nb_epoch = 50\n",
        "    batch_size = 16\n",
        "    num_classes = 6\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}